
<!DOCTYPE html>
<html lang='en'>
<head>
<title>AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio | Qwiklabs</title>
<script>
//<![CDATA[
window.gon={};gon.current_user={"firstname":"DANIEL","lastname":"ENRIQUE SANDOVAL SANCHEZ","fullname":"DANIEL ENRIQUE SANDOVAL SANCHEZ","company":"Coursera","email":"desandovals@liverpool.com.mx","origin":"googlecoursera-run, lti-coursera","subscriptions":0,"id":"40414ff5fc280f833d9acca966912f93","qlCreatedAt":"2020-11-17 20:45:59 UTC","optIn":null,"current_organization_id":null,"current_organization_role":null};gon.segment="j4Im8pqIko0Lxq4wVVZWMPMM0EroHUvb";gon.deployment="googlecoursera-run";gon.content={"type":"Lab","id":2076,"name":"AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio"};
//]]>
</script>
<script>
  dataLayer = [
    {user: gon.current_user},
    {content: gon.content}
  ];
</script>
<script>
  (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer',"GTM-TQR88QK");
</script>
<script>
  EVENT_SOURCE_BASE_URL = "https://googlecoursera-run.qwiklabs.com/nchan-sub?id=";
</script>
<script src="https://cdn.qwiklabs.com/assets/hallofmirrors/polyfills/webcomponents-loader-408088dc333247a761de5f2b2a4ba1cabd2bc36579f83ba92a559eb3682a9b77.js"></script>
<script src="https://cdn.qwiklabs.com/assets/vendor-45d462772c30000424907184f70c7157e95fb6227698d1671c5051818a6f60d8.js"></script>
<script src="https://cdn.qwiklabs.com/assets/application-6874b164d8346f46605fc772a6f7375a39626ffc9f6d168e23a3a8c40bb6fd28.js"></script>
<script src="https://cdn.qwiklabs.com/assets/hallofmirrors/hallofmirrors-b7ff781d00ceebdf75589f58475cea695bafd8d5cc1f3eb4baf6122ed4a4b736.js"></script>
<!--[if lt IE 9]>
<script src='http://html5shim.googlecode.com/svn/trunk/html5.js' type='text/javascript'></script>
<![endif]-->
<!--[endif]>  <![endif]-->
<script type='application/ld+json'>
{
  "@context": "http://schema.org",
  "@type": "WebSite",
  "url": "https://www.qwiklabs.com/",
  "potentialAction": {
    "@type": "SearchAction",
    "target": "https://www.qwiklabs.com/catalog?keywords={search_term_string}",
    "query-input": "required name=search_term_string"
  }
}
</script>
<script id='ze-snippet' src='https://static.zdassets.com/ekr/snippet.js?key=511e4158-0aec-4e3c-b2e6-4daa1769f51e'></script>


<meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="YFUcrufAot94PnInZRVo1NGnoG8UsOkD7Qgvb2ro1LmhXt/ByAsfDM5Rs9OqPGr5uU2QskWvNIEUSfJlgtovOA==" />
<meta content='width=device-width, initial-scale=1.0, maximum-scale=1, user-scalable=0' name='viewport'>
<meta content='1rRsY0INj8RvwB5EF5pwdxt2A2P9aDgAlsICaJ0d5w0' name='google-site-verification'>
<meta content='#3681E4' property='msapplication-TileColor'>
<meta content='/favicon-144.png' property='msapplication-TileImage'>
<meta content='[{&quot;id&quot;:&quot;recaptcha_experiment&quot;,&quot;optimize_id&quot;:&quot;dpViOcLkT3qS4TvL2mRojA&quot;,&quot;title&quot;:&quot;No Recaptcha shown for trusted users&quot;,&quot;variant_index&quot;:0,&quot;variant&quot;:&quot;original&quot;}]' name='active-experiments'>
<meta content='{&quot;userId&quot;:3894861}' name='help-api-product-data'>
<meta content='Architecting Hybrid Infrastructure with Anthos: Configure a multi-service application across multiple clusters with multiple control-planes.' name='description'>
<meta content='Qwiklabs' name='author'>
<meta content='AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio | Qwiklabs' property='og:title'>
<meta content='website' property='og:type'>
<meta content='/favicon-144.png' property='og:image'>
<meta content='Qwiklabs' property='og:site_name'>
<meta content='Architecting Hybrid Infrastructure with Anthos: Configure a multi-service application across multiple clusters with multiple control-planes.' property='og:description'>
<meta content='/qwiklabs_logo_900x887.png' property='og:logo' size='900x887'>
<meta content='/qwiklabs_logo_994x187.png' property='og:logo' size='994x187'>


<link href='/favicon-32.png' rel='shortcut icon'>
<link color='#3681E4' href='/favicon-svg.svg' rel='mask-icon'>
<link href='/favicon-180.png' rel='apple-touch-icon-precomposed'>



<link rel="stylesheet" media="screen" href="https://fonts.googleapis.com/css?family=Oswald:400|Roboto+Mono:400,700|Roboto:300,400,500,700|Google+Sans:300,400,500,700|Google+Sans+Display:400|Material+Icons|Google+Material+Icons" />


<link rel="stylesheet" media="all" href="https://cdn.qwiklabs.com/assets/application-cf67fd00dd904ecce1e24779d7504aefc7fbd5d00696246fa80212743a81bf07.css" />



</head>
<body class='lab-show l-full no-nav application-new focuses focuses-show lab-show l-full no-nav '>
<noscript>
<iframe height='0' src='https://www.googletagmanager.com/ns.html?id=GTM-TQR88QK' style='display:none;visibility:hidden;' width='0'></iframe>
</noscript>
<span class='hidden' id='flash-sibling-before'></span>

<div class='header-container'>
<div class='header'>
<ql-icon-button class='js-nav-toggle header__nav-panel-button l-mrm'>menu</ql-icon-button>
<div class='header__title'>
<ql-icon-button label="Back" href="https://www.coursera.org/" id="d9d101dda49bedd8" target="_self">arrow_back</ql-icon-button><div class="mdl-tooltip" data-mdl-for="d9d101dda49bedd8">Back</div>

<h1 class='headline-5'>
AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio
</h1>
</div>
<div class='header__actions'>
<ql-icon-button class='header__button--search js-header-search-bar-button'>search</ql-icon-button>
<ql-icon-button id='control-panel-target' style='display: none;'>
dashboard
</ql-icon-button>
<ql-menu for='control-panel-target' id='control-panel-menu'></ql-menu>

<ql-icon-button id='help-menu-button'>help</ql-icon-button>
<div class='mdl-tooltip js-tooltip' data-mdl-for='help-menu-button'>
Help
</div>
<ql-menu for='help-menu-button' id='help-menu'>
<ql-menu-item>
<ql-help context='lab' data-analytics-action='opened_help' data-analytics-label='lab' productdata='{&quot;userId&quot;:3894861}'>
Help Center
</ql-help>
</ql-menu-item>
<ql-menu-item>
<a target="_blank" class="ql-body-1" href="https://support.google.com/qwiklabs/contact/contact_us">Email support</a>
</ql-menu-item>
<ql-menu-item>
<a class='ql-body-1' onClick='ql.chat.open()'>Chat support</a>
</ql-menu-item>
</ql-menu>

<ql-icon-button id='language'>language</ql-icon-button>
<div class='mdl-menu mdl-menu__bottom-right mdl-js-menu elevation-3' for='language'>
<a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="ar" href="/focuses/15531272?locale=ar&amp;parent=lti_session">العربية‬‎
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="de" href="/focuses/15531272?locale=de&amp;parent=lti_session">Deutsch
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="en" href="/focuses/15531272?locale=en&amp;parent=lti_session">English
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="es" href="/focuses/15531272?locale=es&amp;parent=lti_session">español (Latinoamérica)
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="fr" href="/focuses/15531272?locale=fr&amp;parent=lti_session">français
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="id" href="/focuses/15531272?locale=id&amp;parent=lti_session">bahasa Indonesia
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="it" href="/focuses/15531272?locale=it&amp;parent=lti_session">Italiano
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="ja" href="/focuses/15531272?locale=ja&amp;parent=lti_session">日本語
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="ko" href="/focuses/15531272?locale=ko&amp;parent=lti_session">한국어
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="pl" href="/focuses/15531272?locale=pl&amp;parent=lti_session">Polski
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="pt_BR" href="/focuses/15531272?locale=pt_BR&amp;parent=lti_session">português (Brasil)
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="pt_PT" href="/focuses/15531272?locale=pt_PT&amp;parent=lti_session">português (Portugal)
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="ru" href="/focuses/15531272?locale=ru&amp;parent=lti_session">русский
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="tr" href="/focuses/15531272?locale=tr&amp;parent=lti_session">Türkçe
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="zh" href="/focuses/15531272?locale=zh&amp;parent=lti_session">简体中文
</a><a class="mdl-menu__item locale-link" data-analytics-action="changed_locale" data-analytics-label="zh_TW" href="/focuses/15531272?locale=zh_TW&amp;parent=lti_session">繁體中文
</a></div>
<button class='icon-button' id='my_account'>
<ql-avatar></ql-avatar>
</button>
<ql-menu for='my_account' open>
<div class='my-account-menu'>
<ql-avatar class='l-mtl l-mbl' size='120'></ql-avatar>
<div class='my-account-menu__user-info l-mbl'>
<h4 class='ql-subhead-1'>DANIEL ENRIQUE SANDOVAL SANCHEZ</h4>
<p class='ql-body-2 text--light'>desandovals@liverpool.com.mx</p>
<p class='ql-body-2 text--light'>
</p>
<a class="text--green ql-subhead-2" href="/my_account/payments"><ql-chip positive>
0 Credits
</ql-chip>
</a></div>
<div class='buttons l-mbl'>
<a class="button button--hairline" id="settings" href="/my_account/profile">Settings</a>
</div>
<hr>
<ql-button data-analytics-action='clicked_sign_out' href='/users/sign_out' method='delete'>
Sign Out
</ql-button>
<div class='privacy l-mtl'>
<a class="ql-caption text--light" href="/privacy_policy">Privacy</a>
<span class='ql-caption text--light l-mls l-mrs'>&middot;</span>
<a class="ql-caption text--light" href="/terms_of_service">Terms</a>
</div>
</div>
</ql-menu>

</div>
</div>
<div class='header__search-bar js-header-search-bar'>
<form class="js-search-form-mobile" onsubmit="ql.searchFilter(); return false;" action="/searches/elasticsearch" accept-charset="UTF-8" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="authenticity_token" value="hWWkFMzOlfZ4UmyjJKE4/VXteX4xma4sNJEqn6l/VrpEbmd74wUoJc49rVfriDrQPQdJo2CGc67N0PeVQU2tOw==" />
<input type="text" name="keywords" id="keywords" placeholder="Search" maxlength="255" aria-label="catalog search bar" />
</form>

<ql-icon-button class='js-close-search-bar'>close</ql-icon-button>
</div>
</div>

<nav class='nav-bar'>
<a class="nav-bar__item js-navigation-button" href="/"><ql-icon class='nav-bar__item__icon'>
home
</ql-icon>
<span class='nav-bar__item__label'>
Home
</span>
</a>
<a class="nav-bar__item js-navigation-button" href="/catalog"><ql-icon class='nav-bar__item__icon'>
school
</ql-icon>
<span class='nav-bar__item__label'>
Catalog
</span>
</a>
<a class="nav-bar__item js-navigation-button" href="/my_learning"><ql-icon class='nav-bar__item__icon'>
event_note
</ql-icon>
<span class='nav-bar__item__label'>
My Learning
</span>
</a>
</nav>

<nav class='nav-panel js-nav-panel'>
<div class='nav-panel__logo'>
<div class='logo logo--blue'></div>
</div>
<a title="Home" tabindex="-1" class="nav-panel__item js-navigation-button" href="/"><ql-icon class='nav-panel__item__icon'>
home
</ql-icon>
<div class='nav-panel__item__label'>
Home
</div>
</a>
<a title="Catalog" tabindex="-1" class="nav-panel__item js-navigation-button" href="/catalog"><ql-icon class='nav-panel__item__icon'>
school
</ql-icon>
<div class='nav-panel__item__label'>
Catalog
</div>
</a>
<a title="My Learning" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_learning"><ql-icon class='nav-panel__item__icon'>
event_note
</ql-icon>
<div class='nav-panel__item__label'>
My Learning
</div>
</a>
<div class='nav-panel__spacer'></div>
<a title="Profile" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/profile"><ql-icon class='nav-panel__item__icon'>
account_circle
</ql-icon>
<div class='nav-panel__item__label'>
Profile
</div>
</a>
<a title="Credits &amp; Subscriptions" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/credits"><ql-icon class='nav-panel__item__icon'>
money
</ql-icon>
<div class='nav-panel__item__label'>
Credits &amp; Subscriptions
</div>
</a>
<a title="Security" tabindex="-1" class="nav-panel__item js-navigation-button" href="/my_account/security"><ql-icon class='nav-panel__item__icon'>
security
</ql-icon>
<div class='nav-panel__item__label'>
Security
</div>
</a>
<div class='nav-panel__spacer'></div>
<a class="nav-panel__item" tabindex="-1" href="#"><ql-help>
<div class='nav-panel__help-item'>
<ql-icon class='nav-panel__item__icon'>help</ql-icon>
<div class='nav-panel__item__label'>
Help
</div>
</div>
</ql-help>
</a><div class='nav-panel__small-links'>
<a tabindex="-1" href="/privacy_policy">Privacy</a>
<a tabindex="-1" href="/terms_of_service">Terms</a>
</div>
</nav>
<div class='nav-panel__overlay js-nav-toggle'></div>

<main class='js-main'>
<div class='l-main-wrapper' id='main-wrapper'>







<ql-drawer-container class='js-lab-state' data-analytics-payload='{&quot;label&quot;:&quot;AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio&quot;,&quot;lab_name&quot;:&quot;AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio&quot;,&quot;classroom_name&quot;:null,&quot;deployment&quot;:&quot;googlecoursera-run&quot;}' data-focus-id='15531272' data-lab-billing-limit='0.0' data-lab-duration='14400' data-parent='lti_session' data-recaptcha-enabled id='lab-container'>
<ql-drawer id='terminal-drawer' slot='drawer' style='width: calc(100% - 480px)'>
<iframe allow='clipboard-read' class='terminal' id='embedded-resource'></iframe>
</ql-drawer>
<ql-drawer-content class='js-lab-wrapper' id='lab-content' slot='drawer-content'>
<ql-drawer-container id='lab-content-container'>
<ql-drawer id='control-panel-drawer' open slot='drawer' width='320'>
<ql-lab-control-panel class='ql-lab-control-panel__max-height control-panel js-lab-control-panel' connectionFiles='[]' labControlButton='{&quot;disabled&quot;:false,&quot;pending&quot;:false,&quot;running&quot;:false}' labDetails='[]' labTimer='{&quot;ticking&quot;:false,&quot;secondsRemaining&quot;:14400}' studentResources='[]'>
<script src="https://www.recaptcha.net/recaptcha/api.js?render=6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr"   ></script>
        <script>
          // Define function so that we can call it again later if we need to reset it
          // This executes reCAPTCHA and then calls our callback.
          function executeRecaptchaForStartLab() {
            grecaptcha.ready(function() {
              grecaptcha.execute('6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr', {action: 'start_lab'}).then(function(token) {
                setInputWithRecaptchaResponseTokenForStartLab('g-recaptcha-response-data-start-lab', token)
              });
            });
          };
          // Invoke immediately
          executeRecaptchaForStartLab()

          // Async variant so you can await this function from another async function (no need for
          // an explicit callback function then!)
          // Returns a Promise that resolves with the response token.
          async function executeRecaptchaForStartLabAsync() {
            return new Promise((resolve, reject) => {
              grecaptcha.ready(async function() {
                resolve(await grecaptcha.execute('6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr', {action: 'start_lab'}))
              });
            })
          };

                    var setInputWithRecaptchaResponseTokenForStartLab = function(id, token) {
            var element = document.getElementById(id);
            element.value = token;
          }

        </script>
<input type="hidden" name="g-recaptcha-response-data[start_lab]" id="g-recaptcha-response-data-start-lab" data-sitekey="6LeVI8IUAAAAAJNdox5eTkYrw9SbvhZ1TFyv3iHr" class="g-recaptcha g-recaptcha-response "/>

<div class='hidden' id='recaptcha-v2-start-lab' slot='recaptcha'>
<script src="https://www.recaptcha.net/recaptcha/api.js" async defer ></script>
<div data-sitekey="6LeOI8IUAAAAAPkHlMAE9NReCD_1WD81iYlBlCnV" data-callback="recaptchaComplete" data-expired-callback="expireV2Token" class="g-recaptcha "></div>
          <noscript>
            <div>
              <div style="width: 302px; height: 422px; position: relative;">
                <div style="width: 302px; height: 422px; position: absolute;">
                  <iframe
                    src="https://www.recaptcha.net/recaptcha/api/fallback?k=6LeOI8IUAAAAAPkHlMAE9NReCD_1WD81iYlBlCnV"
                    name="ReCAPTCHA"
                    style="width: 302px; height: 422px; border-style: none; border: 0; overflow: hidden;">
                  </iframe>
                </div>
              </div>
              <div style="width: 300px; height: 60px; border-style: none;
                bottom: 12px; left: 25px; margin: 0px; padding: 0px; right: 25px;
                background: #f9f9f9; border: 1px solid #c1c1c1; border-radius: 3px;">
                <textarea id="g-recaptcha-response" name="g-recaptcha-response"
                  class="g-recaptcha-response"
                  style="width: 250px; height: 40px; border: 1px solid #c1c1c1;
                  margin: 10px 25px; padding: 0px; resize: none;">
                </textarea>
              </div>
            </div>
          </noscript>

</div>
</ql-lab-control-panel>
</ql-drawer>
<ql-drawer-content id='lab-instructions' slot='drawer-content'>
<div class='alert alert--fake js-alert'>
<p class='alert__message js-alert-message'></p>
<a class='alert__close js-alert-close'>
<i class='fa fa-times'></i>
</a>
<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='js-lab-content lab-content__renderable-instructions'>
<div class='lab-preamble'>
<h1 class='lab-preamble__title'>
AHYBRID070 Configuring GKE for Multi-Cluster Operation with Istio
</h1>
<div class='lab-preamble__details subtitle-headline-1'>
<span>4 hours </span>
<span>Free</span>
<div class='lab__rating'>
<a href="/focuses/15531272/reviews?parent=lti_session"><div class='rateit' data-rateit-readonly='true' data-rateit-value='3.9473'></div>

</a><a data-target='#lab-review-modal' data-toggle='modal'>
Rate Lab
</a>
</div>
</div>
</div>

<div class='js-markdown-instructions markdown-lab-instructions' id='markdown-lab-instructions'>



<ql-warningbox>
<p><strong>Note:</strong> Use of Anthos components requires a license and
subscription. This lab has been provisioned with a trial license.</p>
<p>Contact your
<a href="https://cloud.google.com/contact" target="blank">Google Cloud
account team</a> for more information on subscriptions.</p>
</ql-warningbox>
<h2 id="step1">Overview</h2>
<p>For applications up to a certain size, all of the microservices comprising the
application can be running on a single orchestration platform (e.g., Kubernetes
cluster). However, for many reasons such as scale, redundancy, compliance, etc.,
most applications will eventually need to be distributed and have some of their
services running elsewhere.</p>
<p>Istio supports many possible topologies for distributing the services of an
application beyond a single cluster, for example:</p>
<ul>
<li>
<p>You can combine the services from more than one cluster into a single
composite service mesh.</p>
</li>
<li>
<p>You can expand the service mesh to include services running on VMs or bare
metal hosts.</p>
</li>
<li>
<p>Services within the mesh can use service entries to access standalone
external services or to access services exposed by another loosely-coupled
service mesh.</p>
</li>
</ul>
<h3>Multicluster service mesh</h3>
<p>A multicluster service mesh is a mesh composed of services running within more
than one underlying cluster but with all services running under a single
administrative control. In a multicluster service mesh, a service named foo in
namespace ns1 of cluster 1 is the same service as foo in ns1 of cluster 2. This
is different from a loosely-coupled service mesh where two clusters may have
different definitions of the same service which will need to be reconciled when
integrating the clusters.</p>
<p>A multicluster service mesh has the advantage that all the services look the
same to clients, regardless of where the workloads are actually running. It’s
transparent to the application whether it’s deployed in a single or multicluster
service mesh. To achieve this behavior, a single logical control plane needs to
manage all services, however, the single logical control plane doesn’t
necessarily need to be a single physical Istio control plane. There are two
possible deployment approaches:</p>
<ul>
<li>
<strong>Multicluster shared control plane</strong>: a single, shared Istio control plane
that can access and configure the services in more than one cluster.</li>
<li>
<strong>Multicluster multi control plane</strong>: multiple Istio control planes that
have replicated service and routing configurations.</li>
</ul>
<p>Even with these two approaches, there are many ways to configure a
multicluster service mesh. In a large multicluster mesh, a combination of the
approaches might even be used. For example, two clusters might share a control
plane while a third has its own. Which approach to use and how to configure it
depends on the requirements of the application and on the features and
limitations of the underlying cloud deployment platform.</p>
<p>In this lab, you configure two clusters: one cluster on GKE, named <code>central</code>,
and one <strong>not</strong> on GKE named <code>remote</code>. You then apply an Istio service mesh
across both clusters using a dual control-plane architecture. Then, you deploy
and use a multi-microservice application with services split to run across
both clusters.</p>
<p><img alt="Hybrid Multicluster Architecture" src="https://cdn.qwiklabs.com/FFVzRi7yZ7HeaQ%2F5u15xvU6XDxuDynWitZIi4orHVoc%3D"></p>
<h3>Objectives</h3>
<p>In this lab, you learn how to perform the following tasks:</p>
<ul>
<li>
<p>Install and configure a multi-cluster mesh</p>
<ul>
<li>Register a GKE and a non-GKE Kubernetes cluster with GKE Hub using GKE Connect</li>
<li>Create secrets on both clusters containing required certificates and keys</li>
<li>Install Anthos Service Mesh on GKE with Citadel and multicluster features enabled</li>
<li>Install Open Source Istio on non-GKE clusters with multicluster features enabled</li>
<li>Install and configure Core DNS</li>
</ul>
</li>
<li>
<p>Deploy and use Hipster Shop in multiple configurations</p>
<ul>
<li>Review the deployments in each cluster</li>
<li>Understand the ServiceEntries in both clusters</li>
<li>Understand service-to-service flow between clusters</li>
<li>Migrate workloads from the non-GKE cluster to the GKE cluster</li>
</ul>
</li>
</ul>
<h2 id="step2">Task 0. Lab Setup</h2>
<p>In this task, you use Qwiklabs and perform initialization steps for your lab.</p>
<h3>Access Qwiklabs</h3>
<p>For each lab, you get a new GCP project and set of resources for a fixed time at no cost.</p>
<ol>
<li>
<p>Make sure you signed into Qwiklabs using an <strong>incognito window</strong>.</p>
</li>
<li>
<p>Note the lab's access time (for example, <img alt="img/time.png" src="https://cdn.qwiklabs.com/aZQJ4BT7uCmM9XR6BTXgTRP1Hfu1T7q6V%2BcnbdEsbpU%3D"> and make sure you can finish in that time block.</p>
</li>
</ol>
<aside> <p>
  There is no pause feature. You can restart if needed, but you have to start at the beginning.
  </p>

</aside>
<ol start="3">
<li>
<p>When ready, click <img alt="img/start_lab.png" src="https://cdn.qwiklabs.com/XE8x7uvQokyubNwnYKKc%2BvBBNrMlo5iNZiDDzQQ3Ddo%3D">.</p>
</li>
<li>
<p>Note your lab credentials. You will use them to sign in to Cloud Platform Console.
<img alt="img/open_google_console.png" src="https://cdn.qwiklabs.com/0d78dhX6IVMVWmixCPPSBbmi5O2GPokCXf1Ps1AkTgI%3D"></p>
</li>
<li>
<p>Click <strong>Open Google Console</strong>.</p>
</li>
<li>
<p>Click <strong>Use another account</strong> and copy/paste credentials for <strong>this</strong> lab into the prompts.</p>
</li>
</ol>
<aside class="warning"><p>
  If you use other credentials, you'll get errors or <strong>incur charges</strong>.
  </p>
</aside>
<ol start="7">
<li>Accept the terms and skip the recovery resource page.</li>
</ol>
<aside class="warning"><p>
  Do not click <strong>End Lab</strong> unless you are finished with the lab or want to restart it. This clears your work and removes the project.
  </p>
</aside>

<p>After you complete the initial sign-in steps, the project dashboard appears.</p>
<p><img alt="GCP Project Dashboard" src="https://cdn.qwiklabs.com/dxfeoOcn1ObyC0BYyoqqqSi4rO%2FeMdbWPFjoK6C0YYk%3D"></p>
<p>Click <strong>Select a project</strong>, highlight your <em>Google Cloud Project ID</em>, and click
<strong>OPEN</strong> to select your project.</p>
<h3>Activate Google Cloud Shell</h3>
<p>Google Cloud Shell is a virtual machine that is loaded with development tools. It offers a persistent 5GB home directory and runs on the Google Cloud.
Google Cloud Shell provides command-line access to your GCP resources.</p>
<ol>
<li>
<p>In GCP console, on the top right toolbar, click the Open Cloud Shell button.</p>
<p><img alt="Cloud Shell icon" src="https://cdn.qwiklabs.com/vdY5e%2Fan9ZGXw5a%2FZMb1agpXhRGozsOadHURcR8thAQ%3D"></p>
</li>
<li>
<p>Click <strong>Continue</strong>.
<img alt="cloudshell_continue.png" src="https://cdn.qwiklabs.com/lr3PBRjWIrJ%2BMQnE8kCkOnRQQVgJnWSg4UWk16f0s%2FA%3D"></p>
</li>
</ol>
<p>It takes a few moments to provision and connect to the environment. When you are connected, you are already authenticated, and the project is set to your <em>PROJECT_ID</em>. For example:</p>
<p><img alt="Cloud Shell Terminal" src="https://cdn.qwiklabs.com/hmMK0W41Txk%2B20bQyuDP9g60vCdBajIS%2B52iI2f4bYk%3D"></p>
<p><strong>gcloud</strong> is the command-line tool for Google Cloud Platform. It comes pre-installed on Cloud Shell and supports tab-completion.</p>
<p>You can list the active account name with this command:</p>
<pre><code>gcloud auth list&#x000A;</code></pre>
<p>Output:</p>
<pre><code class="language-output prettyprint">Credentialed accounts:&#x000A; - &lt;myaccount&gt;@&lt;mydomain&gt;.com (active)&#x000A;</code></pre>
<p>Example output:</p>
<pre><code class="language-Output prettyprint">Credentialed accounts:&#x000A; - google1623327_student@qwiklabs.net&#x000A;</code></pre>
<p>You can list the project ID with this command:</p>
<pre><code>gcloud config list project&#x000A;</code></pre>
<p>Output:</p>
<pre><code class="language-output prettyprint">[core]&#x000A;project = &lt;project_ID&gt;&#x000A;</code></pre>
<p>Example output:</p>
<pre><code class="language-Output prettyprint">[core]&#x000A;project = qwiklabs-gcp-44776a13dea667a6&#x000A;</code></pre>
<ql-infobox>
  Full documentation of <strong>gcloud</strong> is available on
  <a href="https://cloud.google.com/sdk/gcloud" target="_blank">
    Google Cloud gcloud Overview
  </a>.
</ql-infobox>

<h2 id="step3">Task 1. Prepare the lab environment</h2>
<h3>Review the clusters used in this lab</h3>
<p><img alt="Multicluster Lab Environment" src="https://cdn.qwiklabs.com/v7zASn9LPmYKOkBfHC2d0befkL7HxESqIIYyY0GTCpM%3D"></p>
<p>The lab environment has already been partially configured:</p>
<ul>
<li>
<p>A GKE cluster, named <code>central</code>, in the <code>us-central1</code> region.</p>
</li>
<li>
<p>A <em>remote</em> Kubernetes cluster, named <code>remote</code>. This cluster connects to
Anthos in the same way a GKE On-Prem cluster, or a cluster on another cloud
provider, would connect to Anthos. To avoid installing a VMware environment
for this lab, the remote cluster runs on Google Compute Engine,</p>
</li>
</ul>
<h3>Set environment variables and install software</h3>
<ol>
<li>
<p>Run a script to set environment settings:</p>
<pre><code class="language-bash prettyprint">export PROJECT="$(gcloud config list --format 'value(core.project)')"&#x000A;export PROJECT_ID="$(gcloud config list --format 'value(core.project)')"&#x000A;export PROJECT_NUMBER=$(gcloud projects describe ${PROJECT_ID} \&#x000A;--format="value(projectNumber)")&#x000A;export C1_NAME="central"&#x000A;export C1_ZONE="us-central1-b"&#x000A;export C2_NAME="remote"&#x000A;export C2_NAME_BASE="${C2_NAME}.k8s.local"&#x000A;</code></pre>
</li>
<li>
<p>Install <a href="https://github.com/ahmetb/kubectx/blob/master/kubens" target="_blank"><code>kubectx</code></a> /
<a href="https://github.com/ahmetb/kubectx/blob/master/kubens" target="_blank"><code>kubens</code></a> to easily
move between clusters:</p>
<pre><code class="language-bash prettyprint">sudo apt install kubectx&#x000A;</code></pre>
</li>
<li>
<p>Install <a href="https://googlecontainertools.github.io/kpt" target="_blank">kpt</a> to add
configuration to yaml files easily:</p>
<pre><code class="language-bash prettyprint">sudo apt-get install google-cloud-sdk-kpt&#x000A;</code></pre>
</li>
</ol>
<h2 id="step4">Task 2. Register remote Kubernetes cluster with GKE Connect</h2>
<p><img alt="GKE Hub Connect" src="https://cdn.qwiklabs.com/MnJ76U6%2BDvVCI%2F4vkFaluYomT4o1LRYWHQgUM3tIuzg%3D"></p>
<p><strong>GKE Hub</strong> is a centralized dashboard that allows you to view and manage all of
your Kubernetes clusters from one central location. Clusters can be located
within Google Cloud, on other cloud vendors, or on-premises.</p>
<p>The mechanism that enables this centralized management is a standard Pod
deployed to your clusters called the <strong>GKE Connect</strong> agent. The agent is
responsible for reaching out to the GKE Hub APIs, listening for commands,
and providing updates.</p>
<p>GKE Hub requires that the Pods in your cluster are able to reach
<code>www.googleapis.com</code> and <code>gkeconnect.googleapis.com</code>, either directly or
through a configured proxy server.</p>
<h3>Review the existing clusters in Cloud Console</h3>
<ol>
<li>Review existing <strong>Kubernetes Clusters</strong> in Cloud Console from the
<strong>Navigation menu</strong> (<img alt="Navigation menu" src="https://cdn.qwiklabs.com/fXo8j8i%2FKJoMkZ7FeHUYU7Vvu2PQfFZtFbLISSnYEaY%3D">) &gt;
<strong>Kubernetes Engine</strong> &gt; <strong>Clusters</strong>.</li>
</ol>
<p>You may need to click <strong>Refresh</strong>.</p>
<p><img alt="Clusters Central" src="https://cdn.qwiklabs.com/eY83MZU3sO8Xtkco4KmlMdtTBF6V93lPgrG5L03ixfY%3D"></p>
<p>You will only see a single GKE cluster named <code>central</code>. You will not see any
remote clusters yet.</p>
<h3>Check on the <em>remote</em> cluster using <code>kubectl</code>
</h3>
<p>As part of bootstrapping this lab, a Kubernetes cluster was provisioned on
Compute Engine. This <em>simulates</em> a cluster running outside of Google Cloud. The
procedure that follows can be applied to any Kubernetes cluster that can access
the GKE control plane APIs mentioned earlier. For example, this works equally
well on different cloud vendors' conforming Kubernetes clusters or VMWare-based
clusters using the GKE On-Prem binaries.</p>
<ol start="2">
<li>
<p>Set up the Cloud Shell environment for command-line access to your clusters:</p>
<pre><code class="language-bash prettyprint">export SHELL_IP=$(curl -s api.ipify.org)&#x000A;&#x000A;gcloud compute firewall-rules create shell-to-remote \&#x000A;  --allow tcp \&#x000A;  --source-ranges $SHELL_IP&#x000A;&#x000A;gsutil cp gs://$PROJECT_ID-kops-remote/config \&#x000A;  ~/.kube/config&#x000A;</code></pre>
</li>
<li>
<p>Switch <code>kubectl</code> <em>context</em> to <code>remote</code>:</p>
<pre><code class="language-bash prettyprint">kubectx remote=${C2_NAME_BASE}&#x000A;&#x000A;kubectx remote&#x000A;</code></pre>
<ql-infobox>
<p><strong>Note:</strong> <code>kubectx</code> is a tool which sets the
 configuration used by the <code>kubectl</code> command.</p>
</ql-infobox>
</li>
<li>
<p>Verify <code>remote</code> cluster is running:</p>
<pre><code class="language-bash prettyprint">kubectl get nodes&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>NAME                        STATUS   ROLES&#x000A;master-us-central1-a-ndt9   Ready    master&#x000A;nodes-hcs1                  Ready    node&#x000A;nodes-kr83                  Ready    node&#x000A;nodes-nxm4                  Ready    node&#x000A;</code></pre>
</li>
</ol>
<h3>Use a Google Cloud service account to create a private key file</h3>
<p>A JSON file containing Google Cloud service account credentials is required to
register a cluster. It is recommended that a distinct service account be created
for every cluster registration. For this lab exercise, a service account, with a
name based on the project-id, has already been created.</p>
<p>In the following steps, you'll assign
the appropriate Cloud IAM roles to the service account, and you'll create a JSON
private key containing the service account's credentials.</p>
<ol start="5">
<li>
<p>Grant the service account permission to register clusters:</p>
<p>Assign the <code>gkehub.connect</code> Cloud IAM role to the service
account.</p>
<pre><code class="language-bash prettyprint">export GKE_CONNECT_SA=anthos-connect&#x000A;export GKE_SA_CREDS=~/$GKE_CONNECT_SA-creds.json&#x000A;&#x000A;gcloud projects add-iam-policy-binding $PROJECT \&#x000A;    --member="serviceAccount:$PROJECT@$PROJECT.iam.gserviceaccount.com" \&#x000A;    --role="roles/gkehub.connect"&#x000A;</code></pre>
</li>
<li>
<p>Generate and download a private key to use later:</p>
<pre><code class="language-bash prettyprint">gcloud iam service-accounts keys create $GKE_SA_CREDS \&#x000A;  --iam-account=$PROJECT@$PROJECT.iam.gserviceaccount.com \&#x000A;  --project=$PROJECT&#x000A;</code></pre>
</li>
</ol>
<h3>Install Connect Agent on remote cluster</h3>
<p><img alt="Connect Agent Connection" src="https://cdn.qwiklabs.com/QP%2Bw8sYwNkBJUIoM92S22EKppwHju%2F%2BUtRRQpPRc9qs%3D"></p>
<ol start="7">
<li>
<p>Register the remote cluster using <code>gcloud</code>:</p>
<pre><code class="language-bash prettyprint">gcloud container hub memberships register $C2_NAME \&#x000A; --context=$C2_NAME \&#x000A; --service-account-key-file=$GKE_SA_CREDS \&#x000A; --project=$PROJECT&#x000A;</code></pre>
<p>This creates a membership, then installs the Connect Agent.</p>
<p><strong>Output (do not copy)</strong></p>
<pre><code>...&#x000A;Waiting for membership to be created...done.&#x000A;Generating connect agent manifest...&#x000A;Deploying GKE Connect agent to cluster...&#x000A;</code></pre>
<ql-infobox>
<p><strong>Note:</strong> You can also register remote clusters using the
 Cloud Console UI with <strong>Register Cluster</strong>.</p>
</ql-infobox>
</li>
<li>
<p>Review existing <strong>Kubernetes Clusters</strong> in Cloud Console from the
<strong>Navigation menu</strong> (<img alt="Navigation menu" src="https://cdn.qwiklabs.com/fXo8j8i%2FKJoMkZ7FeHUYU7Vvu2PQfFZtFbLISSnYEaY%3D">)
&gt; <strong>Kubernetes Engine</strong> &gt; <strong>Clusters</strong>.</p>
<p><img alt="Clusters Central Remote" src="https://cdn.qwiklabs.com/TJfu58zKBaG9Zi1z4njoJP3bzpk2iYpokp1wOuvc4Qg%3D"></p>
<p>Now you see the <code>remote</code> cluster listed, but you need to log in before
it's you can manage it via the console.</p>
</li>
</ol>
<h3>Create a Kubernetes Service Account (KSA)</h3>
<p>To finalize the registration and connection, you need to authenticate and log
into the <code>remote</code> cluster through the console. Currently, you can authenticate
to an external cluster in one of three ways:</p>
<ul>
<li>Token-based authentication: using a Kubernetes Service Account (KSA) with
proper RBAC roles to authenticate (using its Secret as a token).</li>
<li>Basic authentication: using a username and password.</li>
<li>OpenID Connect.</li>
</ul>
<p>Most Kubernetes clusters with RBAC enabled have basic authentication disabled.</p>
<p>You can use the KSA token method to authenticate to the <code>remote</code> cluster.</p>
<ol start="9">
<li>
<p>Create a KSA that you will use to log in:</p>
<pre><code class="language-bash prettyprint">export KSA=remote-admin-sa&#x000A;kubectl create serviceaccount $KSA&#x000A;</code></pre>
</li>
<li>
<p>Assign it the <code>cluster-admin</code> ClusterRole:</p>
<pre><code class="language-bash prettyprint">kubectl create clusterrolebinding ksa-admin-binding \&#x000A;    --clusterrole cluster-admin \&#x000A;    --serviceaccount default:$KSA&#x000A;</code></pre>
</li>
<li>
<p>Extract the token from its associated Secret:</p>
<pre><code class="language-bash prettyprint">printf "\n$(kubectl describe secret $KSA | sed -ne 's/^token: *//p')\n\n"&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>aSB3aWxsIG5vdCB0cnkgdG8gc3RlYWwgc29tZW9uZSBlbHNlcyB0b2tlbiBhZ2FpbgppIHdpbGwgbm90IHRyeSB0byBzdGVhbCBzb21lb25lIGVsc2VzIHRva2VuIGFnYWluCmkgd2lsbCBub3QgdHJ5IHRvIHN0ZWFsIHNvbWVvbmUgZWxzZXMgdG9rZW4gYWdhaW4KaSB3aWxsIG5vdCB0cnkgdG8gc3RlYWwgc29tZW9uZSBlbHNlcyB0b2tlbiBhZ2FpbgppIHdpbGwgbm90IHRyeSB0byBzdGVhbCBzb21lb25lIGVsc2VzIHRva2VuIGFnYWluCmkgd2lsbCBub3QgdHJ5IHRvIHN0ZWFsIHNvbWVvbmUgZWxzZXMgdG9rZW4gYWdhaW4KaSB3aWxsIG5vdCB0cnkgdG8gc3RlYWwgc29tZW9uZSBlbHNlcyB0b2tlbiBhZ2FpbgppIHdpbGwgbm90IHRyeSB0byBzdGVhbCBzb21lb25lIGVsc2VzIHRva2VuIGFnYWluCmkgd2lsbCBub3QgdHJ5IHRvIHN0ZWFsIHNvbWVvbmUgZWxzZXMgdG9rZW4gYWdhaW4K&#x000A;</code></pre>
<p>That is an excerpt from the KSA token.</p>
</li>
<li>
<p>Copy the value of the token returned to the clipboard. In <strong>Cloud Shell</strong>,
select the token output by carefully selecting the text, <strong>without capturing
any trailing spaces</strong>.</p>
<ql-warningbox>
<p><strong>Important:</strong> Using <code>Ctrl+C</code> or
<code>Command+C</code> will copy over new line breaks from the display,
instead of treating the token as a single line of text.</p>
<p> Simply selecting text in Cloud Shell will put the contents in your
clipboard buffer.</p>
</ql-warningbox>
</li>
</ol>
<h3>Log into the remote cluster</h3>
<ol start="13">
<li>
<p>Open <strong>Kubernetes Clusters</strong> in Cloud Console from the</p>
<p><strong>Navigation menu</strong> (<img alt="Navigation menu" src="https://cdn.qwiklabs.com/fXo8j8i%2FKJoMkZ7FeHUYU7Vvu2PQfFZtFbLISSnYEaY%3D">)
&gt; <strong>Kubernetes Engine</strong> &gt; <strong>Clusters</strong>.</p>
<p><img alt="Clusters Central Remote" src="https://cdn.qwiklabs.com/TJfu58zKBaG9Zi1z4njoJP3bzpk2iYpokp1wOuvc4Qg%3D"></p>
</li>
<li>
<p>Click <strong>Login</strong>.</p>
</li>
</ol>
<ql-infobox>
<p><strong>Note:</strong> Logging into the cluster through Cloud Console is
  specific to the user. If another user logs into the console and has the
  permissions to view Kubernetes clusters, that user would have to log in to
  <code>remote</code> with their own credentials.</p>
<p>In this example, you generated a <code>remote-admin-sa</code>
<a href="https://cloud.google.com/kubernetes-engine/connect/logging-in#user_setup" target="_blank">
  KSA</a> with the <code>cluster-admin</code> ClusterRole. Typically, each
  user would use their own KSA to log into the cluster from Cloud Console.</p>
<p>GKE Connect leverages your end-user credentials and per-user RBAC rules
  for all actions. Users have scoped access to the resources they expect,
  and Kubernetes audit logs will continue to function as required.</p>
</ql-infobox>
<ol start="15">
<li>
<p>Select <strong>Token</strong> as the authentication method.</p>
<p><img alt="Log in to cluster" src="https://cdn.qwiklabs.com/ixubfABEddX1384HoaqpKKriYQIkX7x8gCrIbPYLAUU%3D"></p>
<p>Paste the token value copied from the previous step to the Token field and
Click <strong>Login</strong>. <strong>Kubernetes Clusters</strong> in Cloud Console updates on
success.</p>
<p><img alt="Clusters Green" src="https://cdn.qwiklabs.com/8RVaxzT1Z4IyYULOzbD89JXpEPNBN6u54ahfsjfMSC4%3D"></p>
</li>
</ol>
<h3>Register the central cluster</h3>
<ol start="16">
<li>
<p>The same way as we did before, we will install Connect Agent on the central
cluster, assign a Google Service account to be able to connect to the GKE Hub,
and then register the central cluster.</p>
</li>
</ol>
<pre><code class="language-bash prettyprint"># Get cluster credentials and configure kubectx&#x000A;gcloud container clusters get-credentials ${C1_NAME} --zone ${C1_ZONE}&#x000A;kubectx central=gke_${PROJECT_ID}_us-central1-b_central&#x000A;kubectx central&#x000A;&#x000A;# Create the service account for gke-connect&#x000A;gcloud iam service-accounts create connect-sa&#x000A;&#x000A;# Assign GSA the role it needs&#x000A;gcloud projects add-iam-policy-binding ${PROJECT_ID} \&#x000A;--member="serviceAccount:connect-sa@${PROJECT_ID}.iam.gserviceaccount.com" \&#x000A;--role="roles/gkehub.connect"&#x000A;&#x000A;# Download the service account key&#x000A;gcloud iam service-accounts keys create connect-sa-key.json \&#x000A;  --iam-account=connect-sa@${PROJECT_ID}.iam.gserviceaccount.com&#x000A;&#x000A;# Register the cluster&#x000A;gcloud container hub memberships register ${C1_NAME}-connect \&#x000A;  --gke-cluster=${C1_ZONE}/${C1_NAME}  \&#x000A;  --service-account-key-file=./connect-sa-key.json&#x000A;</code></pre>
<h2 id="step5">Task 3. Understand configuring service mesh multicluster control planes with Anthos Service Mesh and Istio</h2>
<p>Anthos Service Mesh and Istio use <a href="https://www.envoyproxy.io/" target="_blank">Envoy</a> sidecar proxies running inside
each Pod to manage traffic routing and security, as well as to provide
observability for all Services and workloads running inside the cluster.</p>
<p>When an application spans multiple Kubernetes clusters, Services running outside
of the local Kubernetes cluster must be explicitly defined as part of the
service mesh. The multi cluster service mesh architecture can be implemented in
two different ways: <em>multicluster shared control plane</em>, and <em>multicluster dual
control plane</em>.</p>
<h3>Multicluster shared control plane</h3>
<p>In a shared, single, control plane configuration, the service mesh control plane is
deployed on one of the clusters, while all other clusters run a simpler remote
mesh configuration with Envoy proxies. Each remote cluster connects to the shared
service mesh control plane that manages all of the Envoys as a single mesh.</p>
<p>With a shared control plane, the Pod and service IP addresses on multiple
clusters must not overlap. Also, DNS resolution for services on remote clusters
is not automatic. Instead, users need to replicate services on every
participating cluster.</p>
<p>More detailed steps to set up this architecture are available in the
<a href="https://istio.io/docs/setup/kubernetes/install/multicluster/vpn/" target="_blank">Shared control plane (single-network)</a>
instructions on the istio.io website.</p>
<h3>Multicluster multi control plane</h3>
<p>In a multiple control plane configuration, each cluster has it's own
service mesh control plane installation, and each control plane manages its own
endpoints. This is also called multicluster <em>dual control plane</em> when spanning
two clusters.</p>
<p>Using
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/gateway/" target="_blank">Istio gateways</a>,
a common root Certificate Authority (CA), and ServiceEntries, you configure a
single logical service mesh that is composed of the participating clusters. This
approach has no special networking requirements, as long as the Istio ingress
gateways can reach each other across clusters.</p>
<p>More detailed information about this architecture is available in the
<a href="https://istio.io/docs/setup/kubernetes/install/multicluster/gateways/" target="_blank">Multiple control planes</a>
instructions on the istio.io website.</p>
<p>In this lab, you configure a <strong>multicluster dual control plane</strong> environment.</p>
<h2 id="step6">Task 4. Understand the Hipster Shop multi-service application</h2>
<p>In this lab, you will deploy the
<a href="https://github.com/GoogleCloudPlatform/microservices-demo" target="_blank">Hipster Shop</a>
application, a sample 10-tier microservices application, across both Kubernetes
clusters: <code>central</code> and <code>remote</code>. The application is a web-based e-commerce
app where users can browse items, add them to the cart, and purchase them.</p>
<p>Initially, Hipster is deployed with its services split, on a
<strong>multicluster dual control plane</strong> deployment architecture. External user
requests start in the <code>Frontend</code> service, in the <code>central</code> cluster. Near the
end of this lab, you will migrate the services running on <code>remote</code> to run on
the <code>central</code> cluster.</p>
<p><img alt="Hipster Service Split" src="https://cdn.qwiklabs.com/eBmtPrn8mG880iAX9%2BZX6roJjlRCNaZM0xf4C6Lk8zY%3D"></p>
<h2 id="step7">Task 5. Install and configure Anthos Service Mesh &amp; Open Source Istio</h2>
<ol>
<li>
<p>Download the Anthos Service Mesh Software into the current directory:</p>
<pre><code class="language-bash prettyprint"># download anthos service mesh software&#x000A;curl -LO https://storage.googleapis.com/gke-release/asm/istio-1.6.8-asm.9-linux-amd64.tar.gz&#x000A;tar xzf istio-1.6.8-asm.9-linux-amd64.tar.gz&#x000A;cd istio-1.6.8-asm.9&#x000A;export PATH=$PWD/bin:$PATH&#x000A;</code></pre>
</li>
<li>
<p>Create certificates for use in both clusters:</p>
<pre><code class="language-bash prettyprint">&#x000A;# Create namespace and secret on central cluster&#x000A;kubectx central&#x000A;kubectl create namespace istio-system&#x000A;kubectl create secret generic cacerts  \&#x000A;-n istio-system \&#x000A;--from-file=samples/certs/ca-cert.pem \&#x000A;--from-file=samples/certs/ca-key.pem \&#x000A;--from-file=samples/certs/root-cert.pem \&#x000A;--from-file=samples/certs/cert-chain.pem&#x000A;&#x000A;# Create namespace and secret on remote cluster&#x000A;kubectx remote&#x000A;kubectl create namespace istio-system&#x000A;kubectl create secret generic cacerts  \&#x000A;-n istio-system \&#x000A;--from-file=samples/certs/ca-cert.pem \&#x000A;--from-file=samples/certs/ca-key.pem \&#x000A;--from-file=samples/certs/root-cert.pem \&#x000A;--from-file=samples/certs/cert-chain.pem&#x000A;</code></pre>
</li>
</ol>
<ql-infobox>
    For reference:
    <ul>
<li style="margin-top:6px;">
        By default, for each cluster, Citadel generates a self-signed
        <strong>root certificate</strong> and <strong>key</strong>, and uses
        them to sign workload certificates.
      </li>
<li style="margin-top:6px;">
        Citadel <strong>can</strong> also use an operator-specified certificate
        and key to sign workload certificates.
      </li>
<li style="margin-top:6px;">
        In this lab, both the <code>central</code> and <code>remote</code>
        clusters maintain
        separate control planes with separate Citadel services signing their
        respective workloads.
      </li>
<li style="margin-top:6px;"> 
        To establish trust between services <strong>across</strong> clusters, both
        Citadel signing (CA) certificates must be signed by a common <strong>root</strong>
        certificate authority (Root CA).
      </li>
<li style="margin-top:6px;">
        Workloads also need a certificate chain file to <strong>verify</strong> the chain of
        trust of all intermediate CAs between the Citadel signing (CA)
        certificate and the Root CA.
      </li>
<li style="margin-top:6px;">
      This configuration is done using a <strong>Secret</strong> in the Kubernetes cluster.
      </li>
<li style="margin-top:6px;">
        The Secret created for Citadel has the following properties:
        <ul style="margin-top:6px;">
<li style="margin-top:6px;">
            The secret must be named <code>cacerts</code>
</li>
<li style="margin-top:6px;">
            The secret is created from 4 certificate files (provided with
            the lab) which must be named:
            <ul style="margin-top:6px;">
<li style="margin-top:6px;">
<code>root-cert.pem</code>: contains the Root CA. This is the same for the
                    Citadel service in both <code>central</code> and <code>remote</code> clusters. Both
                    Citadel certificates are signed by this Root CA.
              </li>
<li style="margin-top:6px;">
<code>ca-cert.pem</code>: signing (CA) certificate for each Citadel
                    service. These certificates, for both Citadels, must be signed
                    by the Root CA (root-cert.pem).
              </li>
<li style="margin-top:6px;">
<code>ca-key.pem</code>: the private key for the Citadel service on each
                    cluster. These Citadel certificates and private keys are used to
                    sign the workloads within each cluster.
              </li>
<li style="margin-top:6px;">
<code>cert-chain.pem</code>: the chain of trust between the workload
                    certificates and the Root CA. In this example, it only contains
                    the `ca-cert.pem` certificate hence these files are identical.
                    This is how you can establish trust between services running
                    across clusters.
              </li>
</ul>
</li>
</ul>
</li>
<li style="margin-top:6px;">
      The default Citadel installation sets command line options to configure
        the location of certificates and keys based on these predefined secret
        and file names used in the command (i.e., secret named <code>cacert</code>,
        root certificate in a file named <code>root-cert.pem</code>, Citadel key in
        <code>ca-key.pem</code>, etc.)
      </li>
</ul>
</ql-infobox>
<ol start="3">
<li>
<p>Configure the project to use Anthos Service Mesh:</p>
<pre><code class="language-bash prettyprint">curl --request POST \&#x000A;--header "Authorization: Bearer $(gcloud auth print-access-token)" \&#x000A;--data '' \&#x000A;https://meshconfig.googleapis.com/v1alpha1/projects/${PROJECT_ID}:initialize&#x000A;</code></pre>
</li>
<li>
<p>Install Anthos Service Mesh in the central GKE cluster, with tracing and
multicluster enabled:</p>
<pre><code class="language-bash prettyprint">kubectx central&#x000A;&#x000A;# Note that we are downloading the version that will work with Citadel&#x000A;# instead of Anthos Service Mesh CA, so that we can use the same Root CA&#x000A;kpt pkg get \&#x000A;https://github.com/GoogleCloudPlatform/anthos-service-mesh-packages.git/asm-citadel@release-1.6-asm asm&#x000A;&#x000A;&#x000A;# Configure yaml files for install&#x000A;kpt cfg set asm gcloud.container.cluster ${C1_NAME}&#x000A;kpt cfg set asm gcloud.project.environProjectNumber ${PROJECT_NUMBER}&#x000A;kpt cfg set asm gcloud.core.project ${PROJECT_ID}&#x000A;kpt cfg set asm gcloud.compute.location ${C1_ZONE}&#x000A;&#x000A;# Select the installation profile that assumes all clusters in one project&#x000A;kpt cfg set asm anthos.servicemesh.profile asm-gcp&#x000A;&#x000A;# Create a config file to enable Cloud Trace tracing&#x000A;cat &lt;&lt;EOF &gt; tracing.yaml&#x000A;apiVersion: install.istio.io/v1alpha1&#x000A;kind: IstioOperator&#x000A;spec:&#x000A;  meshConfig:&#x000A;    enableTracing: true&#x000A;  values:&#x000A;    global:&#x000A;      proxy:&#x000A;        tracer: stackdriver&#x000A;EOF&#x000A;&#x000A;# Install Anthos Service Mesh with multicluster enabled&#x000A;istioctl install \&#x000A;  -f asm/cluster/istio-operator.yaml \&#x000A;  -f tracing.yaml \&#x000A;  -f manifests/examples/multicluster/values-istio-multicluster-gateways.yaml&#x000A;&#x000A;# Enable the Anthos Service Mesh UI in Cloud Console&#x000A;kubectl apply -f asm/canonical-service/controller.yaml&#x000A;&#x000A;kubectl wait --for=condition=available --timeout=600s deployment \&#x000A;--all -n istio-system&#x000A;</code></pre>
</li>
</ol>
<ql-infobox>
    Now that Anthos Service Mesh is installed on the GKE cluster, you need to
    install Open Source Istio on the remote cluster, configured to operate
    in a multicluster mesh with your <em>central</em> cluster
  </ql-infobox>
<ol start="5">
<li>
<p>Install Istio in the <code>remote</code> cluster</p>
<pre><code class="language-bash prettyprint">&#x000A;# Download istio&#x000A;curl -sL https://istio.io/downloadIstioctl | ISTIO_VERSION=1.6.8 sh -&#x000A;&#x000A;# Configure kubectl to work with remote cluster&#x000A;kubectx remote&#x000A;&#x000A;# Install Istio&#x000A;~/.istioctl/bin/istioctl install \&#x000A;  -f manifests/examples/multicluster/values-istio-multicluster-gateways.yaml&#x000A;</code></pre>
</li>
<li>
<p>Review the Istio operator used in the Istio installation with the
multi-cluster configuration:</p>
<pre><code class="language-bash prettyprint">cat manifests/examples/multicluster/values-istio-multicluster-gateways.yaml&#x000A;</code></pre>
<p>Look for the <code>multiCluster</code> attribute under <code>global</code>.</p>
<p><strong>Output (do not copy)</strong></p>
<pre><code>...&#x000A;multiCluster:&#x000A;  enabled: true&#x000A;...&#x000A;</code></pre>
<p>Istio is configured with the following values for a multicluster mesh:</p>
</li>
</ol>
<ql-infobox>
For reference:
  <ul>
<strong>mTLS</strong> disabled within each service mesh
  <li>
  Provides DNS resolution for <strong>global</strong> services. Any service not running
        within the cluster belongs to a <code>.global</code> domain. More on this in a bit.
  </li>
<li>Enable
        <a href="https://github.com/istio-ecosystem/istio-coredns-plugin" target="_blank">CoreDNS</a>
        to resolve DNS names for services running <strong>outside</strong> of the local cluster.
        More on this in a bit.</li>
<li>Enables multicluster and control plane security.</li>
<li>You use Istio gateways for service-to-service communication between the
        clusters, which requires a Root CA. For this you must
        disable self signed certificates in Citadel.</li>
<li>
        Istio egress gateway enabled for any outbound, out of the service mesh,
        traffic. The Hipster Shop app, used in this lab, requires access to
        public Google APIs to function properly.
        </li>
</ul>
</ql-infobox>
<h2 id="step8">Task 6. Review Service Mesh control planes in the GKE cluster and the non-GKE cluster</h2>
<p>Let's verify that all Istio resources have been created correctly in both
clusters.</p>
<h3>Istio Control planes in the istio-system namespace</h3>
<ol>
<li>
<p>Verify the namespace <code>istio-system</code> was created on <code>central</code> for the
Istio control plane components:</p>
<pre><code class="language-bash prettyprint">kubectx central&#x000A;kubectl get namespaces&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>NAME                       STATUS   AGE&#x000A;asm-system                 Active   4m2s&#x000A;default                    Active   26m&#x000A;gke-connect                Active   13m&#x000A;istio-system               Active   12m&#x000A;kube-node-lease            Active   26m&#x000A;kube-public                Active   26m&#x000A;kube-system                Active   26m&#x000A;</code></pre>
</li>
<li>
<p>Verify the namespace <code>istio-system</code> was created on <code>remote</code> for the
Istio control plane components:</p>
<pre><code class="language-bash prettyprint">kubectx remote&#x000A;kubectl get namespaces&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>NAME                       STATUS   AGE&#x000A;default                    Active   26m&#x000A;gke-connect                Active   19m&#x000A;istio-system               Active   4m54s&#x000A;kube-node-lease            Active   26m&#x000A;kube-public                Active   26m&#x000A;kube-system                Active   26m&#x000A;</code></pre>
</li>
<li>
<p>Verify that the <code>istio-system</code> namespace in <code>central</code> has <strong>isdiod</strong>
running:</p>
<pre><code class="language-bash prettyprint">kubectx central&#x000A;kubectl get po -n istio-system | grep istiod&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>istiod-d5df45c98-v2xvk             1/1     Running     ...&#x000A;istiod-f9c89dcd9-9mkxw             1/1     Running     ...&#x000A;</code></pre>
<p>In the newer versions of Istio, Citadel is no longer it's own deployment,
but rather, it has been integrated in the new istiod component.
<a href="https://istio.io/docs/concepts/security/" target="_blank">Istiod</a> is now the service
responsible for signing and distributing certificates to all Envoy proxies
(workload sidecar proxies, as well as ingress and egress gateway proxies)
in the service mesh.</p>
</li>
<li>
<p>Verify that the <code>istio-system</code> namespace in <code>remote</code> has <strong>isdiod</strong>
running:</p>
<pre><code class="language-bash prettyprint">kubectx remote&#x000A;kubectl get po -n istio-system | grep istiod&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>istiod-d5df45c98-tmp2c             1/1     Running     ...&#x000A;</code></pre>
</li>
<li>
<p>Verify the Istio required
<a href="https://istio.io/docs/setup/kubernetes/install/kubernetes/#installation-steps" target="_blank">Custom Resource Definitions (CRDs)</a>
are present:</p>
<pre><code class="language-bash prettyprint">kubectx central&#x000A;kubectl get crds -n istio-system | grep 'istio.io\|certmanager.k8s.io' | wc -l&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>25&#x000A;</code></pre>
<pre><code class="language-bash prettyprint">kubectx remote&#x000A;kubectl get crds -n istio-system | grep 'istio.io\|certmanager.k8s.io' | wc -l&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>25&#x000A;</code></pre>
</li>
<li>
<p>Verify the Anthos Service Mesh version 1.6.8-asm.9 on <code>central</code>:</p>
<pre><code class="language-bash prettyprint">kubectx central&#x000A;istioctl version -o yaml | grep version&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>golang_version: go1.14.6b4&#x000A;version: 1.6.8-asm.9&#x000A;</code></pre>
</li>
<li>
<p>Verify the Istio version 1.6.8 on <code>remote</code>:</p>
<pre><code class="language-bash prettyprint">kubectx remote&#x000A;~/.istioctl/bin/istioctl version -o yaml | grep version&#x000A;</code></pre>
<p><strong>Output (do not copy)</strong></p>
<pre><code>golang_version: go1.14.2&#x000A;version: 1.6.8&#x000A;</code></pre>
</li>
</ol>
<h2 id="step9">Task 7. Configure DNS to locate services external to a cluster</h2>
<p>In this task, you learn about and configure service name resolution for
services local to your cluster, and services external to your cluster.</p>
<h3>Service names within the local cluster</h3>
<p>The default implementation of Istio automatically discovers all Services running
within the <strong>local</strong> cluster, in which Istio is running, by using the Kubernetes
Service registry.</p>
<p>Services running inside the Kubernetes cluster use a DNS name ending with
a <code>.local</code> domain. For example, <strong>service_A</strong>, running within the cluster, will
have a DNS name of <code>service_A.namespace.svc.cluster.local</code>.</p>
<h3>Service names external to the local cluster</h3>
<p>You can expand the service mesh, beyond the local services, by explicitly
defining
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/service-entry/" target="_blank">ServiceEntries</a>
for Services that are not local to the Kubernetes cluster.</p>
<p>These Services could be running in a VM or, in this case, another Kubernetes
cluster. The Services running outside the cluster are identified using DNS names
belonging to a <code>.global</code> domain.</p>
<p>From this cluster's perspective, a <strong>service_B</strong>, running in a remote cluster,
will have a DNS name of <code>service_B.namespace.global</code>.</p>
<h3>Resolving .local service names using kube-dns</h3>
<p>In Kubernetes, the
<a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/" target="_blank">kube-dns</a>
service is used for name resolution. <code>kube-dns</code> knows how to resolve <code>.local</code>
domain names.</p>
<h3>Resolving .global service names using CoreDNS</h3>
<p>In order for <code>kube-dns</code> to resolve <code>.global</code> domain names, you
create a
<a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/#configuration-of-stub-domain-and-upstream-nameserver-using-coredns" target="_blank">stub domain</a>
and point all DNS queries ending with the <code>.global</code> suffix to the CoreDNS Pod. A
stub domain instructs <code>kube-dns</code> to route all name queries for <code>.global</code> domains
to a different DNS service, in this case, <code>CoreDNS</code>.</p>
<p><code>CoreDNS</code> is an Istio plugin used to serve DNS records out of Istio
<strong>ServiceEntries</strong>. The plugin runs as a separate container in the <code>CoreDNS</code>
pod, serving DNS A records over gRPC to CoreDNS.</p>
<ol>
<li>
<p>Create a <code>kube-dns</code> <strong>ConfigMap</strong> for the <strong>stub</strong> domain that will be
calling services in remote clusters, in both <code>central</code> and <code>remote</code> clusters:</p>
<pre><code class="language-bash prettyprint">&#x000A;# Configure kubectl to work with the central cluster&#x000A;kubectx central&#x000A;&#x000A;# Create and apply a ConfigMap config file&#x000A;kubectl apply -f - &lt;&lt;EOF&#x000A;apiVersion: v1&#x000A;kind: ConfigMap&#x000A;metadata:&#x000A;  name: kube-dns&#x000A;  namespace: kube-system&#x000A;data:&#x000A;  stubDomains: |&#x000A;    {"global": ["$(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP})"]}&#x000A;EOF&#x000A;&#x000A;# Configure kubectl to work with the remote cluster&#x000A;kubectx remote&#x000A;&#x000A;# Create and apply a ConfigMap config file&#x000A;kubectl apply -f - &lt;&lt;EOF&#x000A;apiVersion: v1&#x000A;kind: ConfigMap&#x000A;metadata:&#x000A;  name: kube-dns&#x000A;  namespace: kube-system&#x000A;data:&#x000A;  stubDomains: |&#x000A;    {"global": ["$(kubectl get svc -n istio-system istiocoredns -o jsonpath={.spec.clusterIP})"]}&#x000A;EOF&#x000A;</code></pre>
</li>
<li>
<p>Verify the stub domain created in the <code>kube-dns</code> ConfigMap:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n kube-system get configmap kube-dns -o json | jq '.data'&#x000A;</code></pre>
<p><strong>Output (Do not copy)</strong></p>
<pre><code>{&#x000A;  "stubDomains": "{\"global\": [\"10.4.9.236\"]}\n"&#x000A;}&#x000A;</code></pre>
<p>In this example, <code>10.4.9.236</code> is the Pod IP for the CoreDNS Pod. It will be
different in your clusters.</p>
</li>
</ol>
<h3>CoreDNS setup</h3>
<p>CoreDNS is installed as part of Istio along with a ConfigMap which configures
it to resolve <code>.global</code> domain names.</p>
<ol start="3">
<li>
<p>Inspect the CoreDNS configuration:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n istio-system get configmap coredns -o json | jq -r '.data.Corefile'&#x000A;</code></pre>
<p><strong>Output (Do not copy):</strong></p>
<pre><code>.:53 {&#x000A;      errors&#x000A;      health&#x000A;      # Removed support for the proxy plugin: https://coredns.io/2019/03/03/coredns-1.4.0-release/&#x000A;      grpc global 127.0.0.1:8053&#x000A;      forward . /etc/resolv.conf {&#x000A;        except global&#x000A;      }&#x000A;      prometheus :9153&#x000A;      cache 30&#x000A;      reload&#x000A;    }&#x000A;</code></pre>
</li>
</ol>
<h3>Adding ServiceEntries</h3>
<p>You can add additional services to the Istio service registry using
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/service-entry/" target="_blank"><strong>ServiceEntries</strong></a>.
ServiceEntries are used for services running <strong>outside</strong> of the local cluster.</p>
<p>ServiceEntry describes the attributes of the service, including
DNS names, virtual IPs, ports, protocols, and endpoints.
When you create a
ServiceEntry for a service with a <code>.global</code> domain, <code>kube-dns</code> redirects the DNS
request for that service to CoreDNS which uses the ServiceEntry to resolve to an
IP address. You will create this in the next section when you deploy the Hipster
Shop application, with services across two clusters.</p>
<h2 id="step10">Task 8. Deploy the Hipster Shop application across multiple clusters</h2>
<p>In this task, you install the Hipster Shop app to both clusters. Hipster Shop
consists of
<a href="https://github.com/GoogleCloudPlatform/microservices-demo#service-architecture" target="_blank">10 microservices written in different languages</a>.
In this lab, you split the application across <code>central</code> and <code>remote</code> clusters.</p>
<p>For the overall service architecture of Hipster Shop, return to Task 2, and
review the diagram.</p>
<h3>Install Hipster Shop</h3>
<ol>
<li>
<p>Install the Hipster Shop application on the <code>central</code> and <code>remote</code> clusters:</p>
<pre><code class="language-bash prettyprint">cd $BASE_DIR&#x000A;git clone https://github.com/GoogleCloudPlatform/training-data-analyst&#x000A;cd training-data-analyst/courses/ahybrid/v1.0/AHYBRID081/hipster-shop&#x000A;&#x000A;# Get Istio ingress gateway Ip addresses from both central and remote clusters&#x000A;export GWIP_CENTRAL=$(kubectl --context central get -n istio-system service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')&#x000A;export GWIP_REMOTE=$(kubectl --context remote get -n istio-system service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}')&#x000A;&#x000A;# change context to central cluster&#x000A;kubectx central&#x000A;&#x000A;# Prepare the service-entries yaml to add the remote cluster istio ingress&#x000A;# gateway IP for all services running in the remote cluster&#x000A;export pattern='.*- address:.*'&#x000A;export replace="  - address: "$GWIP_REMOTE""&#x000A;sed -r -i "s|$pattern|$replace|g" central/service-entries.yaml&#x000A;&#x000A;# Create hipster2 namespace and enable istioInjection on the namespace&#x000A;kubectl create namespace hipster2&#x000A;kubectl label namespace hipster2 istio-injection=enabled&#x000A;&#x000A;# Deploy part of hipster app on central cluster in the namespace hipster2&#x000A;kubectl apply -n hipster2  -f central&#x000A;&#x000A;# change context to remote cluster&#x000A;kubectx remote&#x000A;&#x000A;# Prepare the service-entries yaml to add the remote cluster istio ingress gateway IP&#x000A;# for all services running in the remote cluster&#x000A;export pattern='.*- address:.*'&#x000A;export replace="  - address: "$GWIP_CENTRAL""&#x000A;sed -r -i "s|$pattern|$replace|g" remote/service-entries.yaml&#x000A;&#x000A;# Create hipster2 namespace and enable istioInjection on the namespace&#x000A;kubectl create namespace hipster1&#x000A;kubectl label namespace hipster1 istio-injection=enabled&#x000A;&#x000A;# Deploy part of hipster app on remote cluster in the namespace hipster2&#x000A;kubectl apply -n hipster1  -f remote&#x000A;</code></pre>
<p><strong>Output (Do not copy):</strong></p>
<pre><code>###&#x000A;### Deploying hipster app on central and remote clusters&#x000A;###&#x000A;Switched to context "central".&#x000A;namespace/hipster2 created&#x000A;namespace/hipster2 labeled&#x000A;deployment.apps/frontend created&#x000A;deployment.apps/productcatalogservice created&#x000A;deployment.apps/cartservice created&#x000A;deployment.apps/recommendationservice created&#x000A;deployment.apps/loadgenerator created&#x000A;gateway.networking.istio.io/frontend-gateway created&#x000A;virtualservice.networking.istio.io/frontend-ingress created&#x000A;serviceentry.networking.istio.io/adservice-entry created&#x000A;serviceentry.networking.istio.io/checkoutservice-entry created&#x000A;serviceentry.networking.istio.io/currencyservice-entry created&#x000A;serviceentry.networking.istio.io/shippingservice-entry created&#x000A;service/recommendationservice created&#x000A;service/frontend created&#x000A;service/productcatalogservice created&#x000A;service/cartservice created&#x000A;Switched to context "remote".&#x000A;namespace/hipster1 created&#x000A;namespace/hipster1 labeled&#x000A;deployment.apps/emailservice created&#x000A;deployment.apps/checkoutservice created&#x000A;deployment.apps/paymentservice created&#x000A;deployment.apps/currencyservice created&#x000A;deployment.apps/shippingservice created&#x000A;deployment.apps/adservice created&#x000A;serviceentry.networking.istio.io/currency-provider-external created&#x000A;serviceentry.networking.istio.io/whitelist-egress-googleapis created&#x000A;serviceentry.networking.istio.io/frontendservice-entry created&#x000A;serviceentry.networking.istio.io/productcatalogservice-entry created&#x000A;serviceentry.networking.istio.io/cartservice-entry created&#x000A;service/emailservice created&#x000A;service/checkoutservice created&#x000A;service/paymentservice created&#x000A;service/currencyservice created&#x000A;service/shippingservice created&#x000A;service/adservice created&#x000A;</code></pre>
</li>
</ol>
<h3>Hipster Shop services and ServiceEntries</h3>
<p>In this diagram, you can see that most services external to a cluster, will
be identified with ServiceEntries. A few services remain visible only within
their local cluster.</p>
<p><img alt="Hipster ServiceEntries" src="https://cdn.qwiklabs.com/IP4lIlwN5NfXK6SnqdpkRISWei8Ab2D6VrkQt8JPHfM%3D"></p>
<ul>
<li>
<p><strong>central</strong> cluster:</p>
<ul>
<li>Deployments and Services, running <strong>locally</strong>:
<ul>
<li><code>frontend</code></li>
<li><code>productcatalogservice</code></li>
<li><code>cartservice</code></li>
<li><code>recommendationservice</code></li>
<li>
<code>loadgenerator</code> (Deployment only)</li>
<li>ServiceEntries, for <strong>external</strong> services:</li>
<li><code>adservice-entry</code></li>
<li><code>checkoutservice-entry</code></li>
<li><code>currencyservice-entry</code></li>
<li><code>shippingservice-entry</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>remote</strong> cluster:</p>
<ul>
<li>Deployments and Services, running <strong>locally</strong>:
<ul>
<li><code>adservice</code></li>
<li><code>checkoutservice</code></li>
<li><code>currencyservice</code></li>
<li><code>shippingservice</code></li>
<li><code>emailservice</code></li>
<li><code>paymentservice</code></li>
<li>ServiceEntries, for <strong>external</strong> services:</li>
<li><code>frontendservice-entry</code></li>
<li><code>productcatalogservice-entry</code></li>
<li><code>cartservice-entry</code></li>
<li>Additional ServiceEntries:</li>
<li>
<code>currency-provider-external</code>: external API required for
<code>currencyservice</code>
</li>
<li>
<code>whitelist-egress-googleapis</code>: external APIs required for the
Hipster app</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="step11">Task 9. Explore Hipster Shop deployments, services, and pods</h2>
<p>In this task, you ...</p>
<p>In Cloud Console, go to Kubernetes Engine → Workloads.</p>
<ol>
<li>
<p>Review the Hipster Shop services across both clusters.</p>
<p>Open <strong>Workloads</strong> in Cloud Console from the
<strong>Navigation menu</strong> (<img alt="Navigation menu" src="https://cdn.qwiklabs.com/fXo8j8i%2FKJoMkZ7FeHUYU7Vvu2PQfFZtFbLISSnYEaY%3D">)
&gt; <strong>Kubernetes Engine</strong> &gt; <strong>Workloads</strong>.</p>
<p>Use <strong>Filter workloads</strong> to show <code>Namespace:hipster1</code> and
<code>Namespace:hipster2</code>.</p>
<p><img alt="Hipster Workloads" src="https://cdn.qwiklabs.com/e0UT1hN%2FgMAUQAPmez1lvwGCKgrQ20NdfGkm%2FxvIgEs%3D"></p>
<p>🔎 The emailservice workload may show an error status: <em>Does not have minimum availability</em>. You can
safely ignore it in the context of this lab.</p>
</li>
<li>
<p>In <strong>Cloud Shell</strong>, review the Deployments and Services in <code>central</code>:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get all&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>NAME                                         READY   STATUS    RESTARTS   AGE&#x000A;pod/cartservice-6c94f4d84c-gvz27             2/2     Running   0          8h&#x000A;pod/frontend-8fd8b864-74dhm                  2/2     Running   0          8h&#x000A;pod/loadgenerator-78cd88b9dc-lmj9s           2/2     Running   0          8h&#x000A;pod/productcatalogservice-6f6df99f7f-mt97p   2/2     Running   0          8h&#x000A;pod/recommendationservice-5564cbcd4f-76st9   2/2     Running   0          8h&#x000A;&#x000A;NAME                            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE&#x000A;service/cartservice             ClusterIP   10.107.8.19     &lt;none&gt;        7070/TCP   8h&#x000A;service/frontend                ClusterIP   10.107.15.253   &lt;none&gt;        80/TCP     8h&#x000A;service/productcatalogservice   ClusterIP   10.107.13.234   &lt;none&gt;        3550/TCP   8h&#x000A;service/recommendationservice   ClusterIP   10.107.11.85    &lt;none&gt;        8080/TCP   8h&#x000A;&#x000A;NAME                                    DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE&#x000A;deployment.apps/cartservice             1         1         1            1           8h&#x000A;deployment.apps/frontend                1         1         1            1           8h&#x000A;deployment.apps/loadgenerator           1         1         1            1           8h&#x000A;deployment.apps/productcatalogservice   1         1         1            1           8h&#x000A;deployment.apps/recommendationservice   1         1         1            1           8h&#x000A;...&#x000A;</code></pre>
</li>
<li>
<p>In <strong>Cloud Shell</strong>, review the Deployments and Services in <code>remote</code>:</p>
<pre><code class="language-bash prettyprint">kubectl --context remote -n hipster1 get all&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>NAME                                   READY   STATUS    RESTARTS   AGE&#x000A;pod/adservice-6768cf4d69-f8gf7         2/2     Running   0          8h&#x000A;pod/checkoutservice-6cdcdd688c-mgxb6   2/2     Running   0          8h&#x000A;pod/currencyservice-8696bcfb99-gzs8l   2/2     Running   0          8h&#x000A;pod/emailservice-c6dd4c67b-slfgt       2/2     Running   0          8h&#x000A;pod/paymentservice-595b56949f-fmkll    2/2     Running   0          8h&#x000A;pod/shippingservice-79654c47b7-p8wgl   2/2     Running   0          8h&#x000A;&#x000A;NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)     AGE&#x000A;service/adservice         ClusterIP   100.69.236.16    &lt;none&gt;        9555/TCP    8h&#x000A;service/checkoutservice   ClusterIP   100.65.129.168   &lt;none&gt;        5050/TCP    8h&#x000A;service/currencyservice   ClusterIP   100.71.137.33    &lt;none&gt;        7000/TCP    8h&#x000A;service/emailservice      ClusterIP   100.65.90.94     &lt;none&gt;        5000/TCP    8h&#x000A;service/paymentservice    ClusterIP   100.66.97.184    &lt;none&gt;        50051/TCP   8h&#x000A;service/shippingservice   ClusterIP   100.66.199.217   &lt;none&gt;        50051/TCP   8h&#x000A;&#x000A;NAME                              DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE&#x000A;deployment.apps/adservice         1         1         1            1           8h&#x000A;deployment.apps/checkoutservice   1         1         1            1           8h&#x000A;deployment.apps/currencyservice   1         1         1            1           8h&#x000A;deployment.apps/emailservice      1         1         1            1           8h&#x000A;deployment.apps/paymentservice    1         1         1            1           8h&#x000A;deployment.apps/shippingservice   1         1         1            1           8h&#x000A;</code></pre>
</li>
<li>
<p>In <strong>Cloud Shell</strong>, review the
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/gateway/" target="_blank">Gateway</a>:</p>
<p>The <code>frontend</code> service is hosted in the <code>central</code> cluster and is exposed
to external requests via a <strong>Gateway</strong>, and a
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/virtual-service/" target="_blank"><strong>VirtualService</strong></a>.</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get gateway -ojson | jq '.items[].spec'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>{&#x000A;  "selector": {&#x000A;    "istio": "ingressgateway"&#x000A;  },&#x000A;  "servers": [&#x000A;    {&#x000A;      "hosts": [&#x000A;        "*"&#x000A;      ],&#x000A;      "port": {&#x000A;        "name": "http",&#x000A;        "number": 80,&#x000A;        "protocol": "HTTP"&#x000A;      }&#x000A;    }&#x000A;  ]&#x000A;}&#x000A;</code></pre>
<p>All incoming traffic, for any host (wildcard hosts entry), in the cluster on
port 80 is being handled by the Istio <code>ingressgateway</code>.</p>
</li>
<li>
<p>Review the frontend VirtualService:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get virtualservices -ojson | jq '.items[].spec'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>{&#x000A;  "gateways": [&#x000A;    "frontend-gateway"&#x000A;  ],&#x000A;  "hosts": [&#x000A;    "*"&#x000A;  ],&#x000A;  "http": [&#x000A;    {&#x000A;      "route": [&#x000A;        {&#x000A;          "destination": {&#x000A;            "host": "frontend",&#x000A;            "port": {&#x000A;              "number": 80&#x000A;            }&#x000A;          }&#x000A;        }&#x000A;      ]&#x000A;    }&#x000A;  ]&#x000A;}&#x000A;</code></pre>
<p>All incoming traffic, for any host (wildcard hosts entry), in the cluster on
port 80 is being handled by the frontend-gateway, and is directed to the
<code>frontend</code> service on port <code>80</code>.</p>
</li>
<li>
<p>Get the Istio ingress gateway IP address:</p>
<pre><code class="language-bash prettyprint">kubectl --context central get -n istio-system service istio-ingressgateway -o jsonpath='{.status.loadBalancer.ingress[0].ip}'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>104.197.97.256&#x000A;</code></pre>
<p><em>Your IP will be different.</em> Use this IP to access Hipster in the next
Task.</p>
</li>
</ol>
<h2 id="step12">Task 10. Use the Hipster Shop application</h2>
<ol>
<li>
<p>Copy and paste the Istio ingress gateway IP address to a web browser tab.</p>
<p>You should see the Hipster Shop home page, at <code>http://[EXTERNAL_IP]</code>.</p>
<p><img alt="Hipster Shop UI" src="https://cdn.qwiklabs.com/WWPQw8n3Kr7QrrUrca%2BiDBAZq7pe5zWCX10JGmgS%2BJE%3D"></p>
</li>
<li>
<p>Verify that the Hipster app is fully functional, running across 2
Kubernetes clusters in 2 environments.</p>
<p>Browse products, add products to your cart, checkout, etc.</p>
</li>
</ol>
<h2 id="step13">Task 11. Review the deployments in each cluster</h2>
<p>The Services that need to communicate with one another are defined as
environment variables in each Deployment spec.</p>
<p>In this task, you review a few services to see with which other services they
interact.</p>
<ol>
<li>
<p>Inspect the <code>frontend</code> Deployment, in the <code>central</code> cluster.</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get deploy frontend -ojson | jq -r '[.spec.template.spec.containers[].env[]]'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>[&#x000A;  {&#x000A;    "name": "PRODUCT_CATALOG_SERVICE_ADDR",&#x000A;    "value": "productcatalogservice.hipster2.svc.cluster.local:3550"&#x000A;  },&#x000A;  {&#x000A;    "name": "CURRENCY_SERVICE_ADDR",&#x000A;    "value": "currencyservice.hipster1.global:7000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CART_SERVICE_ADDR",&#x000A;    "value": "cartservice.hipster2.svc.cluster.local:7070"&#x000A;  },&#x000A;  {&#x000A;    "name": "RECOMMENDATION_SERVICE_ADDR",&#x000A;    "value": "recommendationservice.hipster2.svc.cluster.local:8080"&#x000A;  },&#x000A;  {&#x000A;    "name": "SHIPPING_SERVICE_ADDR",&#x000A;    "value": "shippingservice.hipster1.global:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "CHECKOUT_SERVICE_ADDR",&#x000A;    "value": "checkoutservice.hipster1.global:5050"&#x000A;  },&#x000A;  {&#x000A;    "name": "AD_SERVICE_ADDR",&#x000A;    "value": "adservice.hipster1.global:9555"&#x000A;  }&#x000A;]&#x000A;</code></pre>
<p>Notice from the <strong>values</strong>, by namespaces <code>hipster1</code> and <code>hipster2</code>, and by
<code>FQDN</code> of <code>.local</code> and <code>.global</code>, that <code>frontend</code> is accessing services
running in multiple clusters.</p>
</li>
<li>
<p>Inspect the <code>checkoutservice</code> Deployment in the <code>remote</code> cluster.</p>
<pre><code class="language-bash prettyprint">kubectl --context remote -n hipster1 get deploy checkoutservice -ojson | jq -r '[.spec.template.spec.containers[].env[]]'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>[&#x000A;  {&#x000A;    "name": "PRODUCT_CATALOG_SERVICE_ADDR",&#x000A;    "value": "productcatalogservice.hipster2.global:3550"&#x000A;  },&#x000A;  {&#x000A;    "name": "SHIPPING_SERVICE_ADDR",&#x000A;    "value": "shippingservice.hipster1.svc.cluster.local:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "PAYMENT_SERVICE_ADDR",&#x000A;    "value": "paymentservice.hipster1.svc.cluster.local:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "EMAIL_SERVICE_ADDR",&#x000A;    "value": "emailservice.hipster1.svc.cluster.local:5000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CURRENCY_SERVICE_ADDR",&#x000A;    "value": "currencyservice.hipster1.svc.cluster.local:7000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CART_SERVICE_ADDR",&#x000A;    "value": "cartservice.hipster2.global:7070"&#x000A;  }&#x000A;]&#x000A;&#x000A;</code></pre>
<p>Again, notice from the <strong>values</strong>, by namespaces <code>hipster1</code> and <code>hipster2</code>,
and by <code>FQDN</code> of <code>.local</code> and <code>.global</code>, that <code>frontend</code> is accessing
services running in multiple clusters.</p>
<p>Each Service defined in the container spec, as environment variables,
either points to a <strong>local service FQDN</strong> or a <strong>ServiceEntry</strong>, for a
service in another cluster.</p>
<p>For the <code>checkoutservice</code>:</p>
<ul>
<li>Local Service: <code>shippingservice.hipster1.svc.cluster.local:50051</code>
</li>
<li>ServiceEntry, in the other cluster: <code>cartservice.hipster2.global:7070</code>
</li>
</ul>
</li>
</ol>
<h2 id="step14">Task 12. Understand the ServiceEntries in both clusters</h2>
<p>In this task, you review all the <strong>ServiceEntries</strong>, and learn about different
types of ServiceEntries.</p>
<p>There are two types of ServiceEntries:</p>
<ul>
<li>MESH_INTERNAL</li>
<li>MESH_EXTERNAL</li>
</ul>
<p><strong>MESH_INTERNAL</strong>: configures <strong>non-local</strong> services as part of the Istio Service
Mesh. Recall that services local to the cluster are automatically added to the
service mesh and hence do not require a ServiceEntry. MESH_INTERNAL
ServiceEntries are required for services running outside of the Kubernetes
cluster that need to be added to the local Istio service mesh.</p>
<p>The outputs below show services running in another cluster which need to
be added to the local cluster's service mesh.</p>
<p><strong>MESH_EXTERNAL</strong>: refers to services that are external to the Istio service
mesh. For example, certain services need access to <code>googleapis.com</code> to function
properly, however you do not need to add googleapis as part of this service
mesh.</p>
<ol>
<li>
<p>Inspect the ServiceEntries in <code>central</code>:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get serviceentries&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>NAME                    HOSTS                               LOCATION        RESOLUTION&#x000A;adservice-entry         [adservice.hipster1.global]         MESH_INTERNAL   DNS&#x000A;checkoutservice-entry   [checkoutservice.hipster1.global]   MESH_INTERNAL   DNS&#x000A;currencyservice-entry   [currencyservice.hipster1.global]   MESH_INTERNAL   DNS&#x000A;shippingservice-entry   [shippingservice.hipster1.global]   MESH_INTERNAL   DNS&#x000A;</code></pre>
</li>
<li>
<p>Inspect the ServiceEntries in <code>remote</code>:</p>
<pre><code class="language-bash prettyprint">kubectl --context remote -n hipster1 get serviceentries&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>NAME                          HOSTS                                                                             LOCATION        RESOLUTION&#x000A;cartservice-entry             [cartservice.hipster2.global]                                                     MESH_INTERNAL   DNS&#x000A;currency-provider-external    [www.ecb.europa.eu]&#x000A;frontendservice-entry         [frontend.hipster2.global]                                                        MESH_INTERNAL   DNS&#x000A;productcatalogservice-entry   [productcatalogservice.hipster2.global]                                           MESH_INTERNAL   DNS&#x000A;whitelist-egress-googleapis   [metadata.google metadata.google.internal accounts.google.com *.googleapis.com]&#x000A;</code></pre>
</li>
<li>
<p>Inspect one of the ServiceEntries for the <code>endpoints</code> field:</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get serviceentry checkoutservice-entry -ojson | jq '.spec.endpoints'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>[&#x000A;  {&#x000A;    "address": "34.68.192.238",&#x000A;    "ports": {&#x000A;      "grpc": 15443&#x000A;    }&#x000A;  }&#x000A;]&#x000A;</code></pre>
<p>This <code>endpoints</code> IP <code>address</code> points to the Istio ingress gateway of the
other cluster. Services use the Istio ingress gateways to communicate
between clusters.</p>
<p>Learn more about
<a href="https://istio.io/docs/reference/config/networking/v1alpha3/service-entry/#ServiceEntry" target="_blank">ServiceEntry</a>
parameters in Istio's documentation.</p>
</li>
</ol>
<h2 id="step15">Task 13. Understand service-to-service flow between clusters</h2>
<p>In this task, you walk through the flow of a request from the <code>frontend</code> service
to the <code>checkout</code> service.</p>
<p><img alt="Service Service Flow" src="https://cdn.qwiklabs.com/qzBxHWVmvxLLM5Slbnr%2BqfACTIceg8HioDEqSgUujLA%3D"></p>
<p>The following steps describe the flow of a request from the <code>frontend</code> service,
in the <code>central</code> cluster to <code>checkoutservice</code>, running in the <code>remote</code> cluster.</p>
<ol>
<li>From <code>frontend</code> Pod, the DNS request goes to the default kube-dns for
<code>checkoutservice.hipster1.global</code>.</li>
<li>As the request is for the <code>.global</code> domain, it is forwarded to the <code>coredns</code>
Pod.</li>
<li>CoreDNS resolves this name using the ServiceEntry for <code>checkoutservice</code>
with the endpoint IP of the <code>remote</code> cluster's Istio ingress gateway IP and
port of 15443.</li>
<li>Request arrives at the <code>remote</code> cluster's Istio ingress gateway proxy on
port 15443, as described in the ServiceEntry.</li>
<li>The gateway for port 15443 is a special
<a href="https://en.wikipedia.org/wiki/Server_Name_Indication" target="_blank">SNI</a>-aware
Envoy pre-configured and installed as part of the multicluster Istio
installation in the previous section. Traffic entering port 15443 gets
load balanced among Pods of the appropriate internal service of the
target cluster. In this case, these are <code>checkoutservice</code> Pods in the
<code>remote</code> cluster running in namespace <code>hipster1</code>. You do not create a
Gateway configuration for port 15443.</li>
</ol>
<p><img alt="Service Service Flow Chart" src="https://cdn.qwiklabs.com/N94aoQIqPe7saErkai57B3MWdpVRM3XMWf8BDqbkFaI%3D"></p>
<h2 id="step16">Task 14. Migrate workloads from the non-GKE cluster to the GKE cluster</h2>
<p>In this task, you migrate the currently split Hipster app into a single
<code>central</code> cluster.</p>
<h3>Move services from remote to central</h3>
<p>There are multiple approaches for migrations. For example, you could create
different versions of all services running in the <code>remote</code> cluster on the
<code>central</code> cluster. Then, you might use
<a href="https://istio.io/docs/concepts/traffic-management/#splitting-traffic-between-versions" target="_blank">Istio version-based routing</a>
to slowly migrate requests from <code>remote</code> to <code>central</code>.</p>
<p>The simplest way to migrate the services off of the <code>remote</code> cluster, to the
<code>central</code> cluster, is to create additional Deployments and services in the
<code>central</code> cluster for each service in <code>remote</code>. Then, you update the
environment variables in the <code>central</code> Deployment specs to point to the locally
running services, instead of the ones with names
<code>[service_name].[namespace].global</code>, in <code>remote</code>.</p>
<ol>
<li>
<p>Move the Hipster services to the <code>central</code> cluster:</p>
<pre><code class="language-bash prettyprint"># Set kubectl to work with the central cluster&#x000A;kubectx central&#x000A;&#x000A;# Apply a config that creates the missing deployments on the central cluster&#x000A;kubectl apply -n hipster2  -f hipster&#x000A;&#x000A;# Delete the service entry resources that point to the remote cluster&#x000A;kubectl delete -n hipster2 -f central/service-entries.yaml&#x000A;&#x000A;# Set kubectl to work with the remote cluster&#x000A;kubectx remote&#x000A;&#x000A;# Delete the deployments on the remote cluster&#x000A;kubectl delete -n hipster1  -f remote&#x000A;</code></pre>
<p><strong>Output (Do not copy):</strong></p>
<pre><code>deployment.apps/productcatalogservice unchanged&#x000A;deployment.apps/cartservice configured&#x000A;deployment.apps/recommendationservice unchanged&#x000A;deployment.apps/emailservice created&#x000A;deployment.apps/checkoutservice created&#x000A;deployment.apps/paymentservice created&#x000A;deployment.apps/currencyservice created&#x000A;deployment.apps/shippingservice created&#x000A;deployment.apps/adservice created&#x000A;deployment.apps/loadgenerator unchanged&#x000A;service/recommendationservice unchanged&#x000A;service/frontend unchanged&#x000A;service/productcatalogservice unchanged&#x000A;service/cartservice unchanged&#x000A;service/emailservice created&#x000A;service/checkoutservice created&#x000A;service/paymentservice created&#x000A;service/currencyservice created&#x000A;service/shippingservice created&#x000A;service/adservice created&#x000A;serviceentry.networking.istio.io "adservice-entry" deleted&#x000A;serviceentry.networking.istio.io "checkoutservice-entry" deleted&#x000A;serviceentry.networking.istio.io "currencyservice-entry" deleted&#x000A;serviceentry.networking.istio.io "shippingservice-entry" deleted&#x000A;Switched to context "remote".&#x000A;deployment.apps "emailservice" deleted&#x000A;deployment.apps "checkoutservice" deleted&#x000A;deployment.apps "paymentservice" deleted&#x000A;deployment.apps "currencyservice" deleted&#x000A;deployment.apps "shippingservice" deleted&#x000A;deployment.apps "adservice" deleted&#x000A;serviceentry.networking.istio.io "currency-provider-external" deleted&#x000A;serviceentry.networking.istio.io "whitelist-egress-googleapis" deleted&#x000A;serviceentry.networking.istio.io "frontendservice-entry" deleted&#x000A;serviceentry.networking.istio.io "productcatalogservice-entry" deleted&#x000A;serviceentry.networking.istio.io "cartservice-entry" deleted&#x000A;service "emailservice" deleted&#x000A;service "checkoutservice" deleted&#x000A;service "paymentservice" deleted&#x000A;service "currencyservice" deleted&#x000A;service "shippingservice" deleted&#x000A;service "adservice" deleted&#x000A;</code></pre>
</li>
</ol>
<h3>Check migrated services</h3>
<ol start="2">
<li>
<p>Review services running in <code>central</code>.</p>
<p>Open <strong>Workloads</strong> in Cloud Console from the
<strong>Navigation menu</strong> ()<img alt="Navigation menu" src="https://cdn.qwiklabs.com/fXo8j8i%2FKJoMkZ7FeHUYU7Vvu2PQfFZtFbLISSnYEaY%3D">)
&gt; <strong>Kubernetes Engine</strong> &gt; <strong>Workloads</strong>.</p>
<p>Then remove <code>hipster1</code> from the workloads filter.</p>
<p><img alt="Hipster Services Migrated" src="https://cdn.qwiklabs.com/G0hUCVmOm81A20fS1noaz1P0sVLcfiAy7iUWlKzgf6U%3D"></p>
<p>All of your Services are now running in the central cluster.</p>
</li>
<li>
<p>Review the Deployment specs for the <code>frontend</code> Deployment.</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get deploy frontend -ojson | jq -r '[.spec.template.spec.containers[].env[]]'&#x000A;</code></pre>
<p>Notice that all references to services are to <code>.local</code> names.</p>
<p>Output (Do not copy):</p>
<pre><code>[&#x000A;  {&#x000A;    "name": "PRODUCT_CATALOG_SERVICE_ADDR",&#x000A;    "value": "productcatalogservice.hipster2.svc.cluster.local:3550"&#x000A;  },&#x000A;  {&#x000A;    "name": "CURRENCY_SERVICE_ADDR",&#x000A;    "value": "currencyservice.hipster2.svc.cluster.local:7000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CART_SERVICE_ADDR",&#x000A;    "value": "cartservice.hipster2.svc.cluster.local:7070"&#x000A;  },&#x000A;  {&#x000A;    "name": "RECOMMENDATION_SERVICE_ADDR",&#x000A;    "value": "recommendationservice.hipster2.svc.cluster.local:8080"&#x000A;  },&#x000A;  {&#x000A;    "name": "SHIPPING_SERVICE_ADDR",&#x000A;    "value": "shippingservice.hipster2.svc.cluster.local:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "CHECKOUT_SERVICE_ADDR",&#x000A;    "value": "checkoutservice.hipster2.svc.cluster.local:5050"&#x000A;  },&#x000A;  {&#x000A;    "name": "AD_SERVICE_ADDR",&#x000A;    "value": "adservice.hipster2.svc.cluster.local:9555"&#x000A;  }&#x000A;]&#x000A;</code></pre>
</li>
<li>
<p>Review the Deployment specs for the <code>checkoutservice</code> Deployment.</p>
<pre><code class="language-bash prettyprint">kubectl --context central -n hipster2 get deploy checkoutservice -ojson | jq -r '[.spec.template.spec.containers[].env[]]'&#x000A;</code></pre>
<p>Output (Do not copy):</p>
<pre><code>[&#x000A;  {&#x000A;    "name": "PRODUCT_CATALOG_SERVICE_ADDR",&#x000A;    "value": "productcatalogservice.hipster2.svc.cluster.local:3550"&#x000A;  },&#x000A;  {&#x000A;    "name": "SHIPPING_SERVICE_ADDR",&#x000A;    "value": "shippingservice.hipster2.svc.cluster.local:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "PAYMENT_SERVICE_ADDR",&#x000A;    "value": "paymentservice.hipster2.svc.cluster.local:50051"&#x000A;  },&#x000A;  {&#x000A;    "name": "EMAIL_SERVICE_ADDR",&#x000A;    "value": "emailservice.hipster2.svc.cluster.local:5000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CURRENCY_SERVICE_ADDR",&#x000A;    "value": "currencyservice.hipster2.svc.cluster.local:7000"&#x000A;  },&#x000A;  {&#x000A;    "name": "CART_SERVICE_ADDR",&#x000A;    "value": "cartservice.hipster2.svc.cluster.local:7070"&#x000A;  }&#x000A;]&#x000A;</code></pre>
<p>All Services now have <code>.local</code> Service address names.</p>
</li>
<li>
<p>Check the Hipster app by browsing the app in your browser again.</p>
<p>Ensure the application is fully functional.</p>
</li>
</ol>
<ql-infobox>
<strong>Congratulations!</strong> You have successfully migrated an app from your hybrid
environment running in two Kubernetes clusters to GKE clusters running in
Google Cloud.
</ql-infobox>
<h2 id="step17">Appendix: Troubleshooting common issues</h2>
<p>The most common issues that arise happen when your Cloud Shell instance
times out, or restarts.</p>
<h3>Problem: I can't access my remote cluster anymore</h3>
<p>For example:</p>
<pre><code class="language-bash prettyprint">$ kubectl get po&#x000A;No resources found.&#x000A;Unable to connect to the server: dial tcp xxx.xxx.xxx.xxx:443: i/o timeout&#x000A;</code></pre>
<p>The source-range for firewall rules were created with the external IP of
your Cloud Shell instance. The firewall rules must be updated to access your
kops remote cluster.</p>
<p>Run the script to update the rule to your current IP:</p>
<pre><code class="language-bash prettyprint">export SHELL_IP=$(curl -s api.ipify.org)&#x000A;&#x000A;gcloud compute firewall-rules create shell-to-remote \&#x000A;  --allow tcp \&#x000A;  --source-ranges $SHELL_IP&#x000A;</code></pre>
<h3>Next Steps</h3>
<ul>
<li>Read more about
<a href="https://istio.io/docs/setup/kubernetes/install/multicluster/gateways/" target="_blank">multicluster multiple control plane architectures</a>
in the Istio docs.</li>
<li>To explore <em>multicluster multiple control plane</em> more, try
<a href="https://github.com/GoogleCloudPlatform/istio-samples/tree/master/multicluster-gke/dual-control-plane" target="_blank">this tutorial</a> which runs 2 clusters
on GKE, in 2 different projects, with 2 different VPC networks.</li>
</ul>
<h2 id="step18">End your lab</h2>
<p>When you have completed your lab, click <strong>End Lab</strong>. Qwiklabs removes the resources you’ve used and cleans the account for you.</p>
<p>You will be given an opportunity to rate the lab experience. Select the applicable number of stars, type a comment, and then click <strong>Submit</strong>.</p>
<p>The number of stars indicates the following:</p>
<ul>
<li>1 star = Very dissatisfied</li>
<li>2 stars = Dissatisfied</li>
<li>3 stars = Neutral</li>
<li>4 stars = Satisfied</li>
<li>5 stars = Very satisfied</li>
</ul>
<p>You can close the dialog box if you don't want to provide feedback.</p>
<p>For feedback, suggestions, or corrections, please use the <strong>Support</strong> tab.</p>

<h5>Manual Last Updated: September 18, 2020</h5>
<h5>Lab Last Tested: October 1, 2020</h5>
<p>Copyright 2021 Google LLC All rights reserved. Google and the Google logo are trademarks of Google LLC. All other company and product names may be trademarks of the respective companies with which they are associated.</p>



</div>
</div>


<div class='hidden js-end-lab-button-container lab-content__end-lab-button'>
<ql-lab-control-button class='js-end-lab-button' running></ql-lab-control-button>
</div>
<!-- / TODO: Move recommendations into the end lab modal -->
</ql-drawer-content>
<ql-drawer end id='outline-drawer' open slot='drawer' width='320'>
<div class='js-lab-content-outline lab-content__outline'>
<a href='#step1'>Overview</a><a href='#step2'>Task 0. Lab Setup</a><a href='#step3'>Task 1. Prepare the lab environment</a><a href='#step4'>Task 2. Register remote Kubernetes cluster with GKE Connect</a><a href='#step5'>Task 3. Understand configuring service mesh multicluster control planes with Anthos Service Mesh and Istio</a><a href='#step6'>Task 4. Understand the Hipster Shop multi-service application</a><a href='#step7'>Task 5. Install and configure Anthos Service Mesh & Open Source Istio</a><a href='#step8'>Task 6. Review Service Mesh control planes in the GKE cluster and the non-GKE cluster</a><a href='#step9'>Task 7. Configure DNS to locate services external to a cluster</a><a href='#step10'>Task 8. Deploy the Hipster Shop application across multiple clusters</a><a href='#step11'>Task 9. Explore Hipster Shop deployments, services, and pods</a><a href='#step12'>Task 10. Use the Hipster Shop application</a><a href='#step13'>Task 11. Review the deployments in each cluster</a><a href='#step14'>Task 12. Understand the ServiceEntries in both clusters</a><a href='#step15'>Task 13. Understand service-to-service flow between clusters</a><a href='#step16'>Task 14. Migrate workloads from the non-GKE cluster to the GKE cluster</a><a href='#step17'>Appendix: Troubleshooting common issues</a><a href='#step18'>End your lab</a>
</div>
</ql-drawer>
</ql-drawer-container>
</ql-drawer-content>
</ql-drawer-container>
<div class='lab-introduction js-lab-introduction is-hidden'>
<div class='lab-introduction__inner'>
<h1 class='headline-1'>Welcome to Your First Lab!</h1>
<ql-icon-button class='js-skip-button'>close</ql-icon-button>
<div class='lab-introduction__video'>
<iframe allow='autoplay; encrypted-media' allowfullscreen frameborder='0' id='lab-introduction' src='https://www.youtube.com/embed/yF7EDXKTmoQ?enablejsapi=1&amp;rel=0&amp;showinfo=0'></iframe>
</div>
<a class='js-skip-button button button--outline'>Skip this video</a>
</div>
</div>



</div>
</main>


<div class='modal fade' id='lab-details-modal'>
<div class='modal-container'>
<div class='mdl-shadow--24dp modal-content'>
<div class='modal-body'>
<p class='l-mbm'>
Architecting Hybrid Infrastructure with Anthos: Configure a multi-service application across multiple clusters with multiple control-planes.
</p>
<p class='small-label l-mbs'>
<strong>
Duration:
</strong>
6m setup
&middot;
240m access
&middot;
180m completion
</p>
<p class='small-label l-mbs'>
<span><strong>Levels: </strong>intermediate</span>
</p>
<p class='small-label'>
<strong>
Permalink:
</strong>
<a href="https://googlecoursera.qwiklabs.com/catalog_lab/2076">https://googlecoursera.qwiklabs.com/catalog_lab/2076</a>
</p>
</div>
<div class='modal-actions'>
<a class='button button--text' data-dismiss='modal'>
Got It
</a>
</div>


</div>
</div>
<iframe class='l-ie-iframe-fix'></iframe>
</div>
<div class='modal fade' id='lab-review-modal'>
<div class='modal-container'>
<div class='mdl-shadow--24dp modal-content'>
<form class="simple_form js-lab-review-form" id="edit_lab_review_12145627" action="/lab_reviews/12145627" accept-charset="UTF-8" data-remote="true" method="post"><input name="utf8" type="hidden" value="&#x2713;" /><input type="hidden" name="_method" value="patch" /><div class='modal-body'>
<p class='label'>
How satisfied are you with this lab?*
</p>
<div class='rateit js-rateit' data-rateit-max='5' data-rateit-min='0' data-rateit-resetable='false' data-rateit-step='1' data-rateit-value='5'></div>
<div class='l-mtm'>

<div class="control-group hidden lab_review_user_id"><div class="controls"><input class="hidden" type="hidden" value="3894861" name="lab_review[user_id]" id="lab_review_user_id" /></div></div>
<div class="control-group hidden lab_review_classroom_id"><div class="controls"><input class="hidden" type="hidden" name="lab_review[classroom_id]" id="lab_review_classroom_id" /></div></div>
<div class="control-group hidden lab_review_lab_id"><div class="controls"><input class="hidden" type="hidden" value="2076" name="lab_review[lab_id]" id="lab_review_lab_id" /></div></div>
<div class="control-group hidden lab_review_focus_id"><div class="controls"><input class="hidden" type="hidden" name="lab_review[focus_id]" id="lab_review_focus_id" /></div></div>
<div class="control-group hidden lab_review_rating"><div class="controls"><input class="hidden js-rating-input" type="hidden" value="2" name="lab_review[rating]" id="lab_review_rating" /></div></div>
<div class="control-group text optional lab_review_comment"><label class="text optional control-label" for="lab_review_comment">Comment</label><div class="controls"><textarea class="text optional" name="lab_review[comment]" id="lab_review_comment">
</textarea></div></div>
</div>
</div>
<div class='modal-actions'>
<a class='button button--text' data-dismiss='modal'>
Cancel
</a>
<input type="submit" name="commit" value="Submit" disabled="disabled" id="submit" data-disabled="false" class="button" data-disable-with="Submit" />
</div>
</form>

</div>
</div>
<iframe class='l-ie-iframe-fix'></iframe>
</div>


<script>
  $( function() {
    ql.initMaterialInputs();
    initChosen();
    initSearch();
    initTabs();
    ql.list.init();
    ql.favoriting.init();
    ql.header.myAccount.init();
    initTooltips();
    ql.autocomplete.init();
    ql.modals.init();
    ql.toggleButtons.init();
    ql.analytics.init();
    ql.labControlPanel.addRecaptchaErrorHandler();
  initLabContent();
  ql.labOutline.links.init();
  initLabReviewModal();
  ql.labAssessment.init();
  ql.labIntroduction.init( true );
  ql.labData.init();
  initLabTranslations( {"are_you_sure":"All done? If you end this lab, you will lose all your work. You may not be able to restart the lab if there is a quota limit. Are you sure you want to end this lab?\n","in_progress":"*In Progress*","ending":"*Ending*","starting":"*Starting, please wait*","end_concurrent_labs":"Sorry, you can only run one lab at a time. To start this lab, please confirm that you want all of your existing labs to end.\n","copied":"Copied","no_resource":"Error retrieving resource.","no_support":"No Support","mac_press":"Press ⌘-C to copy","thanks_review":"Thanks for reviewing this lab.","windows_press":"Press Ctrl-C to copy","days":"days"} );
  ql.labRun.init();
  ql.chat.init();
  ql.initHeader();
  ql.navigation.init();
  ql.navPanel.init();
  ql.navigation.init();
  
  });
</script>

</body>
</html>

